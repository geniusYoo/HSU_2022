# OS STUDY_MID

강의 번호: OS

- chap01 : 운영체제의 시작과 발전
    - 운영체제의 정의
        - 사용자와 컴퓨터 하드웨어 사이에서 중계 역할을 하면서, 프로그램의 실행을 관리하고 제어하는 시스템 소프트웨어
        - 컴퓨터가 켜질 때 메모리에 적재되어 모든 프로그램의 실행을 제어하고 사용자의 요청을 처리해주는 소프트웨어
        - 기술적인 관점 : 운영체제는 컴퓨터의 자원을 독점적으로 관리하는 특별한 소프트웨어
    - 자원
        - 하드웨어 자원 : CPU, 캐시나 메모리, 키보드, 마우스, 디스플레이 등등
        - 소프트웨어 자원 : 응용프로그램들
        - 데이터 자원 : 파일, 데이터베이스 등등
    - 운영체제가 자원을 독점하는 이유
        - 자원에 대한 접근 권한을 운영체제만 가지게 함으로써 사용자들과 응용프로그램들로부터 자원의 훼손을 막고 그들 사이에 자원을 효과적으로 공유할 수 있도록 하기 위함
    - 운영체제는 관리자
        - 사용자에 대한 관리
        - 프로그램의 실행에 관한 일체의 자원 관리
        - 성능 관리
        - 외부의 침입으로부터 안전하게 보호하는 보안 관리
    - 운영체제는 소프트웨어
        - 운영체제는 커널, 도구 프로그램들, 디바이스 드라이버로 구성됨
    - 운영체제의 목적과 기능
        - 목적
            - 사용자의 컴퓨터 사용 편리성
            - 자원의 효율적 사용, 관리
        - 기능
            - CPU, 프로세스 관리
            - 메모리 관리
            - 파일 시스템 관리
            - 장치 관리
            - 네트워크 관리
            - 보안 관리
    - 운영체제와 응용소프트웨어의 차이
        
        
        |  | 운영체제 | 응용소프트웨어 |
        | --- | --- | --- |
        | 목적 | 컴퓨터 하드웨어, 응용소프트웨어 등 자원 관리 | 사용자들의 요구를 충족시킬 수 있도록 설계된 SW |
        | 기능 | 자원 관리와 사용자 관리 | 소프트웨어를 만든 특정 목적만 수행 |
        | 개발언어 | C/C++, 어셈블리어 | C/C++, Java, Python 등등 .. |
        | 실행 | 부팅 시 메모리에 적재, 컴퓨터 끌 때까지 실행 | 사용자가 명령을 통해 실행/종료 |
        | 자원에 대한 접근권한 | 컴퓨터의 모든 자원에 대해 독점적 권한 | 컴퓨터 자원을 사용하려면 반드시 운영체제에게 요청 |
    - 운영체제의 태동
        - 고정 프로그램 컴퓨터 시대 (1940년대)
            - 하나의 프로그램을 컴퓨터 기계에 굳히는 방식
            - 프로그램을 기계에 심으면 이 컴퓨터는 이 프로그램만 실행할 수 있음
                
                → 이런 컴퓨터가 고정 프로그램 컴퓨터
                
        - 내장 프로그래밍 등장 (1945년~)
            - 폰노이만
            - 컴퓨터의 구조를 CPU와 전자식 메모리로 분리하고, CPU가 메모리에서 명령들을 하나씩 CPU 내부로 가져와 처리하는 개념 → 컴퓨터 시스템을 하드웨어와 소프트웨어로 분리한게 큰 의미!
            - 의미
                - 컴퓨터 구조에서 CPU와 메모리를 분리
                - 하드웨어와 소프트웨어의 분리
                - 실행할 프로그램은 메모리에 담고 CPU가 프로그램을 실행하는 방식
                - 프로그램은 입력 장치를 통해 메모리에 적재
        - 프로그램 로더의 발견 : 운영체제 개념의 시작 (1950년대)
            - 첫번째 카드에는 다음 카드에 작성된 프로그램을 메모리로 적재하는 코드만 작성하고
                
                두번째 카드부터 목적하는 프로그램을 작성
                
                → 목적 프로그램을 읽어들이는 코드 : 로더 (loader)
                
        - 원시 운영체제 GM OS 탄생 (1955년)
            - 로더 프로그램을 상대적으로 빠른 테이프에 저장해두고, 필요할 때 실행시켜 펀치 카드의 프로그램을 메모리에 적재
                
                → 이 로더를 모니터, GM OS 라고 부름
                
        - 최초의 운영체제 GM-NAA I/O 탄생 (1956년~1957년)
            - 여러 개발자들이 작성해 쌓아놓은 작업들을 한번에 하나씩 순서대로 메모리에 적재 → 일종의 배치 운영체제
            - 이를 사용함으로써, 프로그램 개발자와 관리자가 분리됨
            - 구조
                - 어셈블러 코드 : 사용자가 작성한 어셈블리어 프로그램 → 기계어 코드로 번역
                - 로더 프로그램 : 사용자 프로그램을 메모리에 적재
                - 공통 입출력 코드 및 메인코드 : 장치 입출력을 다루는 프로그램 코드, 운영체제 시작 코드
            - 응용프로그램 개발자들이 공통으로 필요한 코드를 표준화 → 라이브러리의 개념 등장
    - 운영체제의 발전
        - 배치 운영체제
            - 컴퓨터의 활용률 향상
            - 배치가 하나의 프로그램, 관리자는 입력 컴퓨터를 작동시켜 쌓여있는 여러 배치를 읽어 테이프 장치에 저장
            - 특징
                - 여러 배치 작업들을 모아 한꺼번에 실행하지만 순차적으로 실행
                - 비대화식
                - 프린터에 결과를 출력
                - 작업 요청하고 결과 받는데 시간 오래걸림
        - 다중 프로그래밍 운영체제
            - 여러 프로그램을 메모리에 올려놓고 동시에 실행시키는 기법
            - CPU가 한 프로그램을 실행하다 I/O 발생하면 입출력 완료될 때 까지 CPU가 메모리에 적재된 다른 프로그램을 실행해 CPU의 노는 시간을 줄인다
            - 오늘날의 모든 운영체제는 다중 프로그래밍 운영체제이다.
        - 다중 프로그래밍 도입으로 인한 이슈
            - 큰 메모리 이슈
            - 프로그램의 메모리 할당 및 관리 이슈
            - 메모리 보호 이슈
            - CPU 스케줄링과 컨텍스트 스위칭
            - 인터럽트 개념 도입
            - 동기화
            - 교착상태 해결
        - 시분할 다중 프로그래밍 운영체제
            - 적재된 여러 프로그램을 시간 단위로 나누어 번갈아 실행시키는 기법
            - 비대화식, 느린 응답시간, 오랜 대기시간 → 이들을 해결할 방법이 필요했음
        - 개인용 운영체제
        - 임베디드 운영체제
            - 임베디드 컴퓨터에서 장치들을 제어하고 작동시키는 기능을 수행하고, 장치를 제어하는 프로그램이 원활하게 실행되도록 하는데 목적이 있음
        - 모바일 운영체제
            - 다양한 이동용 혹은 휴대용 장치에서 실행되도록 만들어진 운영체제
        - 실시간 운영체제
            - 실시간 응용프로그램 혹은 태스크가 각각 정해진 데드라인 이내에 처리되도록 보장하는데 목적
- chap02 : 컴퓨터 시스템과 운영체제
    1. 컴퓨터 하드웨어
        - 컴퓨터 하드웨어
            - CPU, Central Processing Unit
                - 기계명령을 실행하는 중앙처리장치, 컴퓨터에 가장 핵심적 장치
                - 전원이 공급될 때 작동 시작해 메모리에 적재된 프로그램 실행
            - 메모리
                - CPU에 의해 실행되는 프로그램 코드와 데이터가 적재되는 공간
                - 프로그램은 실행되기 위해 반드시 메모리에 적재되어야 함
                - 반도체 메모리 RAM
            - 캐시 메모리
                - CPU의 실행 속도를 높이기 위해 CPU와 메모리 사이에 빠른 캐시 메모리를 소량 사용
            - 장치들
                - 입출력 장치, 저장 장치
            - 버스, Bus
                - 컴퓨터 하드웨어들이 서로 데이터를 주고받기 위해 0과 1의 디지털 신호가 지나가는 여러가닥의 선을 다발로 묶어 부르는 용어
                - 여러 도시와 마을을 연결하고 차들이 다니도록 설치된 **도로**로 생각하면 good
                - 3가지의 버스
                    - 주소 버스 : 주소 신호가 지나다니는 버스
                    - 데이터 버스 : 데이터 신호가 지나다니는 버스
                    - 제어 버스 : 제어 신호가 지나다니는 버스
                    - ** 주소 : 저장장치 내에 있는 레지스터들에 대한 번지
            - 시스템 버스와 입출력 버스
                - 시스템 버스 : CPU, 캐시메모리 등 빠르게 작동하는 하드웨어들 사이에 신호를 전송하기 위한 버스
                - 입출력 버스 : 상대적으로 느린 입출력 장치들로부터 입출력 데이터를 전송하기 위한 버스
                - 컴퓨터에도 느린 장치들끼리, 빠른 장치들끼리 버스가 분리되어 구성됨.
                    
                    → 각각에는 3가지 버스(주소,데이터,제어버스) 다있음
                    
        - CPU와 메모리의 관계
            - CPU의 처리 능력 = 컴퓨터의 처리 능력
            - 32bit CPU
                
                = 32개의 주소선을 가진 CPU 
                
                = 2^32개의 서로 다른 주소, 0~2^32-1번지
                
                = 2^32바이트 = 4GB (32bit CPU가 액세스할 수 있는 메모리의 최대 범위)
                
                = 프로그램을 아무리 크게 작성해도 프로그램이 활용할 수 있는 메모리는 4GB를 넘을 수 없다
                
                → 32bit 컴퓨터는 32bit CPU를 가진 컴퓨터
                
                → 32bit 운영체제는 32bit의 주소 체계로 관리하는 운영체제
                
        - CPU 기계 명령 : CPU가 해석하고 실행할 수 있는 기계 명령
            - C 프로그램을 어떤 CPU를 대상으로 컴파일했는지에 따라 기계어가 달라진다
                
                → 컴파일된 코드는 다른 CPU에서 호환성이 없다
                
            - 논리 주소 : 해당 프로그램 내에서 정해진 상대적인 주소 (0번지에서 시작)
                
                ↔ 물리 주소랑은 다름 !
                
        - CPU의 레지스터들
            - PC(Program Counter) : 다음에 실행할 기계 명령의 메모리 주소를 저장하는 레지스터, IP(Instruction Pointer) 레지스터로도 부른다
            - IR(Instruction Register) : 실행하기 위해 메모리에서 읽어 온 명령이 저장된 레지스터
            - SP(Stack Pointer) : 스택영역의 꼭대기 메모리 주소를 저장하는 레지스터
            - 데이터 레지스터들 : 연산에 사용될 데이터들을 저장하는 레지스터들
            - 상태 레지스터(Status Register) : CPU의 상태 정보나 인터럽트 금지 등 제어정보를 가지는 레지스터
        - CPU의 명령 사이클 : CPU가 한 명령을 실행하는 과정
            
            <aside>
            💡 ex) mov eax, [300] : 메모리 300번지의 데이터를 읽어 eax 레지스터에 저장
            
            1. CPU는 PC 레지스터에 저장된 주소 100을 주소 버스에 싣는다
            2. 메모리는 주소 버스로부터 주소 100을 받고, 100번지에 저장된 데이터를 데이터 버스에 싣는다. 이 데이터가 저 명령임
            3. CPU는 데이터 버스에 담긴 바이너리 값을 IR 레지스터에 저장, PC는 다음 명령의 번지로 수정
            4. CPU는 연산에 필요한 데이터를 읽기 위해 데이터의 주소 300을 주소 버스에 싣는다
            5. 메모리는 300번지에 저장된 값 50을 데이터 버스에 싣는다
            6. CPU는 데이터 버스로부터 50을 CPU 내부의 임시 레지스터에 저장한다
            7. CPU는 명령을 해석하고 명령을 실행. 명령 실행 결과 50이 eax 레지스터에 저장된다
            8. 다음 명령의 주소를 PC에 저장
            </aside>
            
        - 스택
            - 운영체제는 프로그램을 실행시킬 때 프로그램마다 4개의 공간을 제공
                - 코드 공간 : 프로그램 코드가 적재되는 메모리 공간
                - 데이터 공간 : 전역 변수들이 적재되는 공간
                - 힙 공간 : 프로그램이 실행중에 동적으로 저장할 데이터를 위한 공간
                - 스택 공간 : 함수가 호출될 때 매개변수나 지역변수, 함수가 실행을 마치고 돌아갈 주소를 저장하기 위한 공간
            - CPU의 SP 레지스터가 현재 실행중인 프로그램의 스택 영역 꼭대기 주소를 가리킴
        - 컨텍스트
            - 어떤 프로그램이 실행중인 일체의 상황 → 메모리와 CPU 레지스터들에 고스란히 담겨있음
            - 현재 실행중인 프로그램의 컨텍스트 = 현재 CPU에 들어있는 레지스터들의 값
            - 현재 실행중인 프로그램을 일시 중단하고 다른 프로그램을 실행시키고자 한다면, 현재 실행중인 프로그램의 컨텍스트를 다른 곳에 복사해두어 다시 실행될 때 이용할 수 있어야 한다.
            - 컨텍스트 스위칭 과정에서 A의 컨텍스트를 구성하는 CPU 레지스터 값들을 프로세스 제어 블록에 저장한다.
            - 레지스터의 양이 많을수록, 컨텍스트 스위칭 속도가 느려진다
            - 저장되는 컨텍스트의 크기는 CPU, 운영체제에 따라 많이 다르다
        - 멀티 코어 CPU
            - 여러개의 코어를 가지고 동시에 여러개의 프로그램을 실행할 수 있는 CPU
            - 코어 : 독립적으로 하나의 프로그램을 실행할 수 있는 완벽한 프로세서
            
    2. 컴퓨터 시스템과 운영체제
        - 운영체제의 계층 구조와 관계
            - 운영체제를 중심으로 하드웨어 영역과 소프트웨어 영역이 나뉘고, 그 둘을 연결한다.
                
                → 계층구조로 설계되는 이유 : 계층 간의 독립성을 확보하기 위해
                
            - 운영체제 - 응용프로그램
                - 응용프로그램은 하드웨어에 접근하려고 할 때 운영체제에게 **시스템 호출**로 운영체제에게 요청
            - 운영체제 - 사용자
                - 사용자에게 편리성 제공
            - 운영체제 - 하드웨어
                - 하드웨어를 제어하는 일은 전적으로 운영체제의 몫
            - 운영체제가 없다면 ?
                - 응용프로그램이나 사용자가 직접 하드웨어를 제어해야 함
                    
                    → 하드웨어에 대한 부족한 지식, 충돌, 관리 미숙, 보안 취약 등의 문제가 발생
                    
        - 운영체제의 기능
            - 프로세스와 스레드 관리
            - 메모리 관리
            - 파일 (시스템) 관리
            - 장치 관리
            - 사용자 인터페이스
            - 네트워킹
            - 보호 및 보안
        - 운영체제와 커널
            
            <aside>
            💡 운영체제는 도구/GUI SW, 커널, 디바이스 드라이버들로 구성되는 소프트웨어이다.
            
            </aside>
            
            - 운영체제 구성
                - 커널 : 운영체제의 핵심 부분
                - 도구 SW : 사용자가 컴퓨터를 쉽게 활용할 수 있도록 돕는 SW, 유틸리티 SW라고도 불림
                - 디바이스 드라이버 : 입출력 장치를 구동/제어, 실질적인 입출력 수행
                - 응용프로그램 — **(System call)** → 운영체제 — **(Interrupt)** → 하드웨어
                - #질문 : CPU도 디바이스 드라이버가 존재하나요 ?
                    
                    → 아니요. 디바이스 드라이버는 입출력 장치를 제어하는 소프트웨어인데, CPU는 입출력 장치가 아니기 때문에 없습니다. 디바이스 드라이버 프로그램을 실행하는 것이 CPU이고, 그 프로그램이 담긴 곳이 메모리라고 생각하면 CPU나 메모리를 제어의 대상이 아닙니다.
                    
            - 커널
                - 부팅 후부터 메모리에 상주하면서 하드웨어를 관리하고 운영체제의 핵심 기능들을 수행
                - 커널이 하는 일들
                    - 프로세스, 스레드 관리
                    - 메모리 관리
                    - 파일(시스템)관리
                    - 디바이스 드라이버를 호출해 장치 입출력
                - 커널 코드 = 함수의 형태로 존재
                - 응용프로그램에서 커널에 있는 함수를 활용하는 유일한 방법 → **시스템 호출**
            - 디바이스 드라이버
                - 장치를 직접 제어하는 소프트웨어
                - 대부분 커널 영역의 메모리에 적재됨
        - 운영체제 커널 인터페이스 : 시스템 호출, 인터럽트
            
            <aside>
            💡 프로그램 — **function call** → 표준 라이브러리
            
                         →  시스템 호출 라이브러리 — **system call** → 커널
            
            </aside>
            
            - 시스템 호출 : 커널과 응용프로그램 사이의 인터페이스
                - 응용프로그램에서 커널코드를 실행하는 유일한 기법
            - 인터럽트 : 커널과 하드웨어 장치 사이의 인터페이스
                - 하드웨어 장치들이 CPU에게 하드웨어 신호를 물리적으로 발생시켜 CPU에게 알리는 기법
                - CPU가 인터럽트 신호를 받으면, 현재 하던 일을 멈추고 인터럽트 서비스 루틴을 실행한다.
                    - 인터럽트 서비스 루틴 : 인터럽트의 요청을 처리하는 코드
    3. 커널과 시스템 호출
        - 응용프로그램의 자원 접근 문제
            - 응용프로그램과 운영체제 커널 메모리 영역을 확실하게 구분하기 위해 → 사용자공간 / 커널공간
            - 응용프로그램이 커널 공간에 함부로 접근할 수 없도록 → 사용자모드 / 커널모드
        - 사용자 공간, 커널 공간
            - 운영체제는 CPU로 액세스할 수 있는 전체 주소 공간을 사용자 공간과 커널 공간으로 분리
            - 왜 나눌까 ?
                - 응용프로그램으로부터 커널 코드와 데이터를 지키기 위해서
                - 커널 공간으로 설정된 메모리 번지를 응용프로그램이 임의로 액세스하는 순간
                    
                    → 응용프로그램 즉시 종료시킴
                    
            - 사용자 공간 크기의 의미
                - 32bit 운영체제에서 사용자 공간의 크기가 2GB로 설정 = 응용프로그램 크기가 최대 2GB
                    
                    → 응용프로그램 크기 = 응용프로그램 코드 + 전역변수들 + 동적할당 메모리 + 스택
                    
            - 사용자 공간, 커널 공간은 **가상 주소 공간**, 실제 메모리 공간 X
                - 운영체제가 응용프로그램에게 만들어준 가상 주소
                - 응용프로그램들은 커널공간을 공유, 사용자 공간은 각 응용프로그램이 독점적으로 사용
                - 가상 주소 공간이어서 각자 0번지에서 시작하는 줄 알고, 각자 2GB씩 쓰는 줄 안다.
                - 운영체제는 각 응용프로그램의 가상 주소 공간을 물리 메모리 공간으로 매핑 테이블을 사용해 매핑 → 물리 메모리를 여러 응용프로그램의 사용자 공간이 나누어 씀
                - 결국, 모든 응용프로그램이 자신만의 사용자 공간을 가지는 셈
        - 사용자 모드, 커널 모드
            - 응용프로그램 코드는 사용자 모드에서, 커널 코드는 커널 모드에서 실행된다.
            - 어떤 모드인지는 CPU 내 모드 레지스터에 설정됨
            
            |  | 사용자 모드 | 커널 모드 |
            | --- | --- | --- |
            | CPU의 메모리 액세스 범위 | 사용자 공간에 국한 | 커널 공간을 포함한 모든 메모리 공간 |
            | CPU의 하드웨어 액세스 여부 | X | O |
            | CPU가 처리 가능한 명령 | 특권 명령을 제외한 모든 명령 | 특권 명령을 포함한 모든 명령 |
            | 오류 발생 시 처리 | 사용자 프로그램만 실행 종료 | 시스템에 심각한 오류 → 시스템 종료 |
            | CPU 모드 비트 | 1 | 0 |
            - 사용자 모드 : 응용프로그램이 커널공간에 접근하지 못하게 하려고 존재
                - CPU는 사용자 모드에서 특권 명령을 실행 못함
            - 커널 모드
                - CPU는 커널 모드에서 모든 메모리 공간 액세스 가능
                - 특권 명령 실행 가능 → 특권 모드, 감독자 모드라고도 불림
        - 사용자 모드 → 커널 모드
            - 시스템 호출
            - 인터럽트 발생
            
            → 이 두가지 경우에 전환이 일어남
            
        - 특권 명령
            - 운영체제 → CPU에게 명령
            - I/O 명령
                - 입출력 장치나 저장장치 제어, 읽기 쓰기에 사용되는 CPU 기계 명령
                - 하드웨어 장치를 직접 접근하므로 커널모드에서 실행되어야 하는 특권 명령이다
            - Halt 명령
                - 커널이 현재 처리할 작업이 없을 때, Halt 명령으로 CPU 작동을 중지시키고 CPU를 유휴 상태로 만든다.
            - 인터럽트 플래그 ON/OFF
                - CPU는 인터럽트를 받으면 인터럽트 플래그(CPU 안의 레지스터)를 확인해서 받을지 말지 결정
                - 이걸 응용프로그램에서 건드리게 되면 인터럽트를 전혀 받을 수 없는 상태가 될 수 있기 때문에 커널 모드에서, 커널 코드에 의해서만 허용된다
            - 타이머 설정
            - 컨텍스트 스위칭
        - Issues
            - 사용자 모드, 커널 모드는 CPU에 의해 구현? 커널에 의해 구현?
                - CPU에 의해 구현되어 운영체제가 활용하는 기능
            - CPU가 커널 모드에서 실행되는 시간과 사용자 모드에서 실행되는 시간을 알 수 있을까 ?
                - 보통 응용프로그램이 실행되는 경우라면, 사용자 모드의 시간 비율이 높아야 함
                - 커널 모드 시간 비율 높다는 건 현재 아무 작업도 이루어지지 않고 있을 때 커널 모드에서 실행되는 시스템 유휴 프로세스 때문일 수 있다
        - 커널의 실체
            - 컴파일된 바이너리 형태
            - 함수들의 집합
            - 실행 단위가 아니고 그저 커널 공간에 적재된 함수, 자료구조들
            - CPU가 app1 응용프로그램을 실행하던 중 시스템 호출을 통해 커널 모드로 바뀌어서 커널 모드를 실행중이다. 현재 어떤 프로세스가 실행중 ? → app1 프로세스
            - 시스템 관리 기능을 하도록 만들어진 함수와 데이터의 집합. 스스로 실행되는 프로세스 X
            - 커널이 프로세스들을 스케줄링 ? Xxx → 시스템호출, ISR에 의해 커널 내 스케줄링 함수 호출
            - 커널이 실행 중이다 ? Xxx → 커널코드가 실행되고 있을 뿐
            - 커널은 스택이나 힙을 가진다 ? Xxx → 커널 스택은 응용프로그램에게 속한 것
        - 라이브러리
            - 표준 라이브러리
            - 시스템 호출 라이브러리 : 운영체제 커널과 밀접한 관계, 함수들의 이름이 운영체제마다 다름
                
                → 여기 들어있는 함수들을 시스템 호출 함수, 또는 커널 API (Application Programming Interface) 라고 부름
                
        - 사용자 코드와 라이브러리 코드의 링킹
            - 응용프로그램 = 사용자가 작성한 함수들 + 이들에 의해 호출되는 라이브러리 함수들 링킹되어 하나의 실행 파일을 이룸
            - 이들이 모두 사용자 공간에 함께 있으며 사용자 함수, 라이브러리 함수 모두 사용자 모드에서!
            - 라이브러리 활용 → 함수 호출, function call
            - 커널 기능 활용 → 시스템 호출, system call
        - 함수 호출로 라이브러리 활용
            - 같은 주소공간 내에서 한 함수가 다른 함수의 코드를 실행하는 과정
            - 커널 모드로 안바뀜, 사용자 모드에서 실행
            - 표준 라이브러리 → 시스템 호출 라이브러리 호출할 때도 function call! 커널모드로 안바뀜!
        - 시스템 호출로 커널 코드 호출
            - 시스템 호출 함수는 시스템 호출 번호로 커널 함수를 구분한다, 이름 X
            - 시스템 호출은 CPU 모드를 커널 모드로 바꾸고 → 시스템 호출 핸들러 (커널 공간 내에 미리 정해진 주소에 있음) 코드를 실행하는 과정
        - **시스템 호출 ****
            - 사용자 공간의 코드에서 커널 공간의 코드를 호출하는 과정, kernel call 로도 불림
            - CPU마다 시스템 호출을 일으키는 특별한 기계 명령이 있음 = 시스템 호출 CPU 명령
            
            <aside>
            💡 ex) 응용 프로그램에서 read() 시스템 호출 함수를 이용해 파일을 읽는 과정
            
            1. 사용자가 작성한 코드는 파일을 읽기 위해 read() 호출 → read() : 파일을 읽는 시스템 호출 함수
            2. 커널 내에는 시스템 호출 표에 시스템 호출 번호를 인덱스로 해 커널 함수의 주소가 저장되어 있음. read()는 시스템 호출 번호 7과 함께 읽을 byte수 등 sys_read()에게 전달할 값들을 미리 정해진 CPU 레지스터에 저장한다
            3. read()는 시스템 호출 명령을 실행
            4. CPU는 사용자모드 → 커널모드 전환, 시스템 호출 핸들러 함수로 점프
            5. 시스템 호출 핸들러는 현재 응용프로그램이 생성될 때 미리 할당된 커널 스택에 현재 CPU의 모든 레지스터 값을 저장
            6. 시스템 호출 핸들러는 CPU 안의 특정 레지스터로부터 시스템 호출 번호 7을 알아내고 시스템 호출 표에서 sys_read() 함수의 주소를 알아내 호출
            7. sys_read() 커널 함수는 디스크로부터 파일 데이터를 읽음
            8. 시스템 호출 핸들러는 커널 스택에 저장해둔 CPU 레지스터 값들을 복귀시키고 작업을 끝낸 후 응용프로그램으로 돌아감
            9. 시스템 호출 핸들러 함수에서 sysret 기계 명령을 실행하고 CPU는 커널 모드에서 사용자 모드로 바꾸고 read() 함수로 돌아간다
            10. read() 함수는 자신을 호출한 응용프로그램으로 돌아간다
            </aside>
            
            - 함수 호출 VS 시스템 호출
                
                
                |  | 함수 호출 | 시스템 호출 |
                | --- | --- | --- |
                | 메모리 영역 | 사용자 영역의 코드에서 사용자 영역의 함수 호출 | 사용자 영역의 코드에서 커널 함수 호출 |
                | CPU 실행 모드 | 사용자 모드 | 사용자 모드에서 커널 모드로 전환 |
                | 비용 | 함수 호출에 따른 비용 | 커널 모드로 전환하는 등 함수 호출에 비해 큰 비용 |
            - fread() 와 read() 비용 비교
                
                “txt 파일을 10번 읽어들인다”
                
                - fread() 10번 → read() 1번 → 시스템 호출 1번 → 9번 버퍼 복사
                - read() 10번 → 시스템 호출 10번
                - fread() 사용하는게 약 8배 더 빠름
    4. 운영체제와 인터럽트
        - 인터럽트 : 입출력 장치들이 비동기적인 사건을 CPU에게 알리는 행위
            - 하드웨어 인터럽트 : 입출력 장치들이 전기적으로 신호 보냄
            - 소프트웨어 인터럽트
        - CPU와 APIC
            - 일반적으로 CPU에는 인터럽트 수신 핀이 1개 뿐이여서 여러 입출력 장치로부터 인터럽트를 받기 위해 CPU와 입출력 장치 사이에 APIC (인터럽트 제어기, Advanced Programmable Interrupt Controller) 가 사용된다
            - APIC
                - I/O APIC : 입출력 장치로부터 직접 인터럽트 신호를 받음
                - Local APIC : I/O APIC로부터 정보를 받아 CPU의 INTR 핀에 인터럽트 신호 발생시킴
        - 인터럽트 벡터 : 약 256개의 인터럽트에 대해 ISR의 주소를 저장하고 있는 테이블이다
            - 커널 영역에 저장되고 커널 코드에 의해서만 수정
            - 부팅시에 만들어짐
        
        <aside>
        💡 인터럽트 처리 과정
        
        1. CPU는 응용프로그램 실행중
        2. 사용자의 키 입력 → 키보드는 CPU에게 전기적 신호 빵
        3. I/O APIC가 신호를 받아 IRQ에 설정된 인터럽트 벡터와 인터럽트를 처리할 타켓 코어의 Local APIC 번호를 메시지로 APIC 버스에 실어 보냄
        4. Local APIC 메시지를 받아서 CPU의 INTR 핀에 인터럽트 신호를 발생시키고 수신한 벡터는 내부에 저장해둠
        5. INTR 신호를 받은 CPU는 Local APIC로부터 인터럽트 벡터를 읽는다
        6. CPU는 커널 모드로 전환, 인터럽트 벡터 테이블로부터 N번 항목에 저장된 ISR의 주소를 알아내고 현재 CPU으가 실행중인 응용프로그램의 컨텍스트를 스택에 저장. 플래그 레지스터의 IF 비트를 0으로 설정해 CPU가 다른 인터럽트를 받지 않도록 함
        7. CPU는 N번 ISR로 점프해서 실행하고 키보드에서 키 값을 읽어 커널에 만들어진 키보드 버퍼에 저장. 키보드 ISR 개발자는 push명령으로 서비스루틴 내에서 사용할 레지스터들을 스택에 저장
        8. pop명령으로 레지스터 복귀. Local APIC에게 인터럽트 처리 끝났음을 알림. iret명령으로 컨텍스트 복귀시키고 IF도 이전으로, CPU도 사용자 모드로 전환
        </aside>
        
        - ISR
            - 인터럽트 서비스 루틴은 인터럽트 핸들러라고 부르기도 함
            - 디바이스 드라이버나 커널 코드에 들어있고 임베디드 컴퓨터의 경우 보드의 ROM에 들어있음
            - 디바이스 드라이버는 장치와 커널 사이에 제어명령과 데이터를 전달하는 인터페이스 역할
        - 인터럽트의 역할
            - 입출력 장치가 처리를 완료하는 시점을 통보하는 것
            - 인터럽트가 없다면? 입출력 작업을 시킨 후 응용프로그램이나 운영체제는 입출력이 완료되었는지를 계속 검사하면서 꼼짝없이 기다려야 한다. → polling, 폴링은 CPU에 의해서 처리되기 때문에 이때 다른 작업을 할 수가 없다
            - 입출력 장치와 CPU가 동시에 각자 일 → CPU 활용률 증가, 시스템 처리율 증가
- chap03 : 프로세스와 프로세스 관리
    1. 프로세스
        - 프로그램과 프로세스 ? 프로세서 ?
            - 프로그램 : 하드디스크나 USB 등 저장장치에 저장된 실행 가능한 파일
            - 프로세스 : 프로그램이 메모리에 적재되어 실행 중일 때
            - 프로세서 : CPU, 그래픽 프로세서, 입출력 프로세서와 같은 하드웨어 처리기
        - 프로세스의 특징
            - 운영체제는 프로세스마다 고유한 번호를 할당
            - 프로세스에 관한 정보는 운영체제 커널에 의해 관리
            - **프로세스들은 서로 독립적인 메모리 공간으로 가지므로, 다른 프로세스의 영역에 접근할 수 없다**
            - 프로세스는 실행-대기-잠자기-실행-종료 등 생명주기를 가짐
        - 프로그램의 다중 인스턴스
            - 프로그램이 실행될 때마다 독립된 프로세스가 생성 →  프로그램의 다중 인스턴스
            - 이들은 완전히 별개의 프로세스들로 다뤄짐
            - 동일한 프로그램의 다중 인스턴스 프로세스들은 프로그램 코드가 적재된 메모리 영역 공유
        - 프로세스 주소 공간
            - CPU 주소 공간 = CPU의 주소선 개수
            - 프로세스 구성
                - 코드 영역 : 프로세스 코드가 적재되는 영역, 텍스트 영역으로도 불림
                - 데이터 영역 : 프로세스의 전역 변수들, 정적 변수들 적재되는 영역
                - 힙 영역 : 프로세스가 실행중에 동적 할당받는 영역
                - 스택 영역 : 함수가 호출될 때 지역변수, 매개변수 등이 저장되는 영역
                
                → 프로세스 코드 영역과 데이터 영역의 크기는 프로세스 실행 중에 변하지 않음. 실행파일에 결정된 상태로 적재되어있음
                
            - 프로세스 주소 공간 = CPU 주소 공간
                - 프로세스 주소 공간은 커널 공간도 포함 → 커널 함수를 실행하는 건 프로세스니까
                - 사용자 공간이 시작되는 0번지부터 시작 (논리공간, 가상공간)
                - 힙은 데이터 영역에서 시작해 주소가 큰 쪽으로 자라고, 스택은 사용자 공간의 끝에서 시작해 주소가 작은 쪽으로 자란다
                    
                    → 둘이 만나면 메모리 부족!
                    
                - CPU가 액세스할 수 있는 전체 공간 = 프로세스 주소 공간
            - 프로세스의 크기 VS 프로세스 주소 공간의 크기
                - 프로세스의 크기 : 프로세스가 주소 공간 내에서 현재 사용하고 있는 코드,데이터,힙,스택 영역을 합친 크기, 실행 중에 계속 변함, 사용자 공간의 최대 범위까지 동적할당 받으면서 스택, 힙 영역을 늘려갈 수 있음
                - 프로세스 주소 공간의 크기 : 프로세스가 액세스할 수 있는, 커져갈 수 있는 전체 영역
            - **프로세스 주소 공간은 가상 공간**
                - 코드에서 사용하는 번지, malloc()의 리턴주소 등은 모두 가상 주소
                - 프로세스를 구성하는 영역들은 물리메모리의 여러 공간에 흩어져 있다
                - 운영체제는 각 프로세스마다 프로세스의 가상 주소 공간과 물리 메모리의 물리 주소 공간을 연결하는 매핑 테이블을 둠
                - 프로세스의 매핑 테이블에는 커널의 물리 메모리 주소를 가진 항목이 있음
                    
                    → 가상 공간의 커널 영역과 진짜 커널 영역을 연결해야 하니까
                    
            - 프로세스들 사이에 가상 주소 공간이 충돌 ?
                - Xxx ,, 프로세스는 자신의 매핑 테이블을 통해 물리 메모리에 접근하며, 각 프로세스의 영역은 운영체제에 의해 물리 메모리의 서로 다른 공간에 배치되므로 충돌 X
                
    2. 커널의 프로세스 관리
        - 운영체제 커널은 시스템 전체에 하나의 프로세스 테이블을 두고 모든 프로세스의 정보를 관리
            
            → 커널 영역에 존재, 시스템에 1개
            
        - 커널은 프로세스 생성할 때마다 PCB 생성해 프로세스의 정보를 저장
        - 프로세스 테이블, PCB → 커널공간에 생성, 커널만이 액세스 가능
        - PCB
            - PID, 프로세스 번호 : 프로세스를 식별하는 고유 번호, 0과 양의 정수만 사용
            - PPID, 부모 프로세스 번호
            - Process State, 프로세스 상태 정보 : New, Running, Ready ...
            - Process Context : 레지스터들의 값이 PCB에 저장됨
            - 스케줄링 정보 : 프로세스 우선순위, 프로세스가 사용한 CPU시간 등등
            - Exit Code, 종료 코드 : 프로세스가 종료할 때, 종료 이유를 부모 프로세스에게 전달하기 위한 정수 값, 반드시 전달해야 함
            - Per-process open file table, 프로세스의 오픈 파일 테이블: 프로세스가 실행 중에 열어 놓은 파일에 관한 정보들
            - 메모리 관리를 위한 정보들
            - 프로세스 사이의 통신 정보들
            - 회계 정보
            - 프로세스의 소유자 정보
        - 프로세스의 생명주기와 상태 변이
            - New
                - 프로세스를 생성하는 시스템 호출 (fork)이 실행되면 프로세스 생성
                - 커널은 새 프로세스의 코드,데이터를 메모리에 적재하고 PCB를 만들어 프로세스 테이블에 등록
                - PCB에는 프로세스 상태를 New라고 기록
            - Ready
                - 프로세스가 스케줄링을 기다리는 준비 상태
                - Ready상태의 프로세스들은 커널의 Ready Queue에 들어가고 커널은 프로세스를 선택한다
                    
                    → 이 과정이 프로세스 스케줄링 또는 CPU 스케줄링
                    
                - Ready 상태가 되는 경우
                    - New 상태에서 Ready Queue에 삽입될 때
                    - Running 상태에서 타임슬라이스 경과, 양보할 때
                    - 입출력 장치, 저장 장치로부터 요청한 작업이 완료되었을 때
            - Block/Wait
                - 프로세스가 자원을 요청하거나 입출력을 요청하고 완료를 기다리는 상태
                - 프로세스가 Running 상태에서 파일 읽기, 자원 요청 등의 시스템 호출을 일으키면 커널은 현재 스로세스 상태를 Blocked 또는 Wait 상태로 만든다
            - Terminated/Zombie
                - 프로세스 종료하면 커널은 프로세스가 차지했던 메모리, 자원들 모두 반환, 열어놓은 파일 닫음
                - 부모 프로세스가 종료코드를 읽어갈 때 까지 Terminated/Zombie 상태로 유지
                - 메모리 다 날아가고 프로세스 테이블 항목과 PCB만 남음 → 좀비 프로세스
            - Terminated/Out
                - 부모 프로세스가 zombie 상태의 자식 프로세스의 종료 코드를 읽어갈 때 커널은 좀비 프로세스의 PCB를 시스템에서 제거, 프로세스 테이블의 항목도 제거 → 시스템에서 완전히 사라짐
        - 프로세스 스케줄링
            - 실행중인 여러 프로세스들 중 CPU를 할당할 프로세스를 결정하는 과정
            - 이제 실행단위는 스레드, 프로세스는 프로세스에 속한 스레들에게 공유 자원을 제공하는 컨테이너로 그 역할이 바뀜
    
    1. 프로세스의 계층 구조
        - 운영체제는 모든 프로세스들을 부모-자식의 계층 관계로 관리
        - 모든 프로세스는 부모 프로세스에 의해 생성, 무조건 시스템 호출로 생성됨 (시조 프로세스#0 제외)
        - #0, #1, #2
            - #0 : 모든 프로세스들의 조상
                - 리눅스 : idle process, swapper
                    - 부팅에 관여 X, 무한 루프를 돌며 아무 일도 안함
                    - 모든 프로세스가 블록상태여서 시스템에 실행시킬 프로세스가 아예 없는 상황을 안만드려고 존재. 실행시킬 프로세스가 없을 때 실행시킴
                - Windows : system idle process
                    - 시스템 유휴 프로세스
            - #1  : init process
                - 부팅 후 실행되는 모든 사용자 프로세스들의 조상
            - #2 : kthreadd
                - 커널 모드에서 실행되는 모든 커널 프로세스들의 조상
        - 부모-자식 프로세스의 실행 관계
            - 프로세스의 생성, 종료에 사용되는 시스템 호출 함수들
                - fork() : 자식 프로세스 생성
                - exit() : 현재 프로세스의 종료를 처리
                - wait() : 부모가 자식 프로세스가 종료할 때까지 기다림
            - 그림 그리기
        - 좀비 프로세스
            - 종료하였지만, 부모가 종료코드를 읽지 않은 상태로 시스템에 남아 있는 프로세스
            - 부모 프로세스는 wait()를 호출해서 자식의 종료코드를 읽어 아예 종료시켜야 함
            - 자식이 exit()을 호출하면 부모에게 자식의 죽음을 부모에게 통보한다 → 부모가 통보를 받았을 때 wait()을 안부르면 자식은 계속 좀비 상태로 남아있게 됨
            - Windows에서는 CloseHandle(자식프로세스핸들) 시스템 호출을 통해 자식을 완전히 소멸
        - 고아 프로세스
            - 부모가 먼저 종료한 자식 프로세스들
            - 부모 프로세스가 종료할 때, 커널(exit()코드)는 자식 프로세스 있는지 확인하고 커널은 자식을 init프로세스에게 입양시킴, 운영체제에 따라 모든 자식프로세스 강제종료 하기도 함
        - Background / Foreground Process
            - Background Process : 사용자와 대화가 없는 채로 실행되는 프로세스
            - Foreground Process : 터미널 사용자로부터의 입출력을 독점하는 프로세스
        - CPU 집중 프로세스, I/O 집중 프로세스
            - CPU 집중 프로세스
                - 프로세스 작업이 대부분 계산 중심적인 일로 구성되어 실행의 많은 부분에 CPU 활용될 때
                - 이미지 처리, 신경망에서 학습하는 인공지능 등
                - CPU의 속도가 성능을 좌우, CPU 바운드 프로세스라고도 함
            - I/O 집중 프로세스
                - 프로세스 작업이 대부분 파일 입출력이나 네트워크 전송 등 입출력 작업인 경우
                - I/O작업을 기다리는 시간이 대부분 → CPU를 사용하는 비중이 매우 낮음
                - 입출력 장치의 속도가 성능을 좌우, I/O 바운드 프로세스라고도 함
            - **운영체제는 I/O 집중 프로세스의 스케줄링 우선순위를 더 높게 다룬다**
                
                → 왜? : I/O 집중 프로세스를 먼저 실행시키면 입출력 요청을 대기하는 동안, 다른 프로세스에게 CPU를 할당할 수 있어서 I/O장치와 CPU가 동시에 활용되어 시스템 자원이 효율적으로 사용되고, 사용자 응답 시간이 줄어들며 시스템 처리율이 높아지기 때문이다.
                
    2. 프로세스 제어
        - 프로세스가 생성되는 경우
            - 시스템 부팅 과정에서 생성
            - 로그인 시 쉘 프로세스 생성
            - 사용자 명령에 따라 응용프로그램 프로세스 생성
            - 배치 프로세스 생성
            - 다중처리를 위해 자식 프로세스 생성
            
            → 생성 방법은 운영체제에 따라 다르지만, 시스템 호출로 생성됨
            
        - 프로세스가 생성되는 과정
            
            <aside>
            💡
            
            - 새로운 PID번호 할당
            - PCB 구조체 생성
            - 프로세스 테이블에 새 항목 할당
            - 새로 할당된 테이블에 PCB 연결
            - 프로세스를 위한 메모리 공간 할당 (코드,데이터,힙,스택)
            - 할당받은 메모리 공간에 프로세스 코드, 데이터 적재
            - PCB에 프로세스 정보 기록
            - PCB에 프로세스 상태를 Ready로 표시하고 준비큐에 넣어 차후 스케줄 되게 함
            </aside>
            
        
        - fork()로 자식 프로세스 생성
            
            ```cpp
            #include <stdio.h>
            #include <sys/types.h>
            #include <sys/wait.h>
            #include <unistd.h>
            
            int main() {
                    pid_t pid;
                    int i, sum=0;
            
                    pid = fork(); // 자식프로세스 생성
               if(pid > 0) { // 부모 프로세스에 의해 실행되는 코드
                 printf("부모프로세스: fork()의 리턴 값 = 자식프로세스 pid = %d\n", pid);
                            printf("부모프로세스: pid = %d\n", getpid());
                            wait(NULL); // 자식 프로세스가 종료할 때까지 대기
                            printf("부모프로세스종료\n");
                            return 0;  
               }
                    else if(pid == 0) { // 자식 프로세스에 의해 실행되는 코드
                printf("자식프로세스: fork()의 리턴 값 pid = %d\n", pid);
                            printf("자식프로세스: pid = %d, 부모프로세스 pid = %d\n", getpid(), getppid());
               for (i=1; i<=100; i++)
                                    sum += i;
                            printf("자식프로세스: sum = %d\n", sum);
                            return 0;  
              }
              else { // fork() 오류
                            printf("fork 오류");
                            return 0;
                    }
            }
            
            ----------------------------------------------------------------
            결과
            $ gcc -o forkex forkex.c
            $ ./forkex
            부모프로세스: fork()의 리턴 값 = 자식프로세스 pid = 29138
            부모프로세스: pid = 29137 //1
            자식프로세스: fork()의 리턴 값 pid = 0
            자식프로세스: pid = 29138, 부모프로세스 pid = 29137 //2
            자식프로세스: sum = 5050
            부모프로세스종료
            $
            
            // 1,2 중 누가 먼저 실행될 지는 모름!
            ```
            
            - 부모 프로세스의 fork() 리턴 값은 자식 프로세스의 pid임
            - 자식 프로세스의 리턴 값은 0
                
                → 코드는 둘이 완전 동일하지만, 조건문을 다르게 진입 !
                
        - 프로세스 오버레이와 exec()
            - 프로세스 오버레이 : 현재 실행중인 프로세스의 주소공간에 새로운 응용프로그램을 적재해 실행, exec() 시스템 호출이 사용됨
            - 자식 프로세스 만들고 execlp() 사용해서 새로운 응용프로그램 적재, 기존 프로세스의 정보는 사라지지만 자식,부모 프로세스의 pid는 동일
            - 부모 프로세스 A에다가 내가 자식으로 쓰고싶은 프로그램 B가 있을 때 A 프로세스에서 fork를 실행해 자식을 만들고 exec()을 통해 프로그램B를 A의 자식 프로세스로 만드는 경우
        - 프로세스 종료와 프로세스 종료 대기
            - `void exit (int status) → 현재 프로세스를 종료시키고 종료코드 status를 부모에게 전달`
                
                <aside>
                💡 프로세스 종료 과정
                
                1. exit()을 호출한 프로세스에게 할당한 모든 메모리와 자원 반환, 열어놓은 파일,소켓 닫음
                2. PCB 내 프로세스 상태를 Terminated/Zombie로 바꾸고 종료코드를 PCB에 저장
                3. 현재 프로세스의 모든 자식 프로세스들을 init프로세스에게 입양시킴
                4. 현재 프로세스의 부모에게 자식의 죽음을 알리는 SIGCHLD 신호를 보냄
                </aside>
                
            - 종료 코드의 범위, 의미
                - 종료코드 : 프로세스가 종료한 상태나 이유를 부모에게 전달하기 위한 것
                - 0~255 사이의 1바이트 숫자, 정상종료는 0 / 1~255는 개발자가 종료 이유를 임의로 정함
                - -1을 종료코드로 리턴하면 -1은 0xff 이므로 양의정수로 255가 전달됨
                - wait()으로 자식프로세스 종료 대기와 종료코드 읽기
                    
                    ```cpp
                    child.c
                    
                    #include <stdio.h>
                    
                    int main() {
                            printf("I am  a child\n");
                            return 100;
                    }
                    
                    ———————————————————————————————————————————
                    waitex.c
                    
                    #include <stdio.h>
                    #include <sys/types.h>
                    #include <sys/wait.h>
                    #include <unistd.h>
                    
                    int main() {
                            pid_t pid;
                            int status;
                    
                            pid = fork(); // 자식프로세스 생성
                    
                            if (pid > 0) { // 부모 프로세스 코드
                                    printf("부모프로세스: 자식의 종료를 기다림\n");
                                    wait(&status); // 자식프로세스 종료 대기. status에 종료 코드 받음
                                    printf("부모프로세스: child의 종료 코드=%d\n",WEXITSTATUS(status));
                                    return 0;
                            }
                            else if (pid == 0) { // 자식 프로세스 코드
                                    execlp("./child", "child", NULL); // child를 자식프로세스로 실행
                            }
                            else { // fork() 오류
                                    printf("fork 오류");
                                    return 0;
                            }
                    }
                    
                    ———————————————————————————————————————————
                    결과
                    
                    $ gcc -o child child.c
                    $ gcc -o waitex waitex.c
                    $  ./waitex
                    부모프로세스: 자식의 종료를 기다림
                    I am a child
                    부모프로세스: child의 종료 코드=100
                    $
                    ```
                    
- chap04 : 스레드와 멀티스레딩
    1. 프로세스의 문제점
        - 프로세스 생성의 큰 오버헤드 : 프로세스 생성에 너무 오랜 시간이 걸림
        - 프로세스 컨텍스트 스위칭의 큰 오버헤드
        - 프로세스 사이의 통신 어려움 : 커널 메모리나 커널에 의해 마련된 메모리 공간을 이용해 데이터를 주고 받아야 함. 이는 커널의 직접적인 지원 → 운영체제 사이의 호환성 떨어짐, 개념 복잡, 속도 느림..
    2. 스레드의 개념
        - 왜 생겼을까 ?
            - 프로세스보다 작은 실행 단위가 필요해
            - 프로세스 생성/소멸에 오버헤드가 너무 커
            - 컨텍스트 스위칭 빠르게
            - 프로세스 사이에는 통신이 어렵잖아
        - 스레드는 실행 단위, 스케줄링 단위
            - 개발자에게는 작업을 만드는 단위, 운영체제에게는 실행 단위, CPU를 할당하는 스케줄링 단위
            - 주소공간을 가진 실체, 실행이 운영체제에 의해 제어
            - 스레드마다 PCB를 두고 스레드를 독립된 단위로 다룸
            - 스레드를 함수가 호출해주는 게 아니라 **CPU가 직접 실행**
        - 프로세스는 스레드들의 컨테이너
            - 프로세스는 스레드들을 담는 컨테이너
            - 스레드는 독립적으로 존재 X, 프로세스 안에 존재해야 함
            - 프로세스가 생성되면 자동으로 1개의 메인 스레드가 생김
        - 프로세스는 스레드의 공유 공간
            - 스레드들은 프로세스의 주소공간을 나누어 사용
            - 스레드가 동적할당 받는 곳 = 프로세스의 힙
            - 프로세스가 속한 스레드들끼리 상호 데이터를 주고 받을 수 있음
        - 스레드는 함수로 작성
            - 스레드가 실행할 작업은 함수로, 사용할 데이터는 함수 내 변수로 만들면 됨
            - 함수를 만든다고 자동으로 스레드 되는 건 X, 운영체제에게 이 함수를 스레드로 만들어줘 요청
                
                → 운영체제가 TCB 하나 만들고, 함수의 시작주소 TCB에 기록. 이 TCB가 스케줄링되면 기록된 주소에서 실행 시작됨. 
                
                → 스레드 생성 = 커널 내 TCB가 생성된다는 것
                
                → 운영체제는 스레드 단위로 스케줄링
                
            - TCB 6개가 있다면, 커널은 CPU 스케줄링을 할 때 6개의 독립적이고 실행가능한 TCB 중 하나를 선택해서 실행한다
        - 스레드로 만든 함수가 종료하면 스레드 종료, 스레드 종료되면 스레드 관련 정보 모두 제거, 자원이나 메모리도 시스템에서 다 제거됨
        - 스레드 만들기
            - 코드
                
                ```cpp
                #include <pthread.h> // pthread 라이브러리를 사용하기 위해 필요한 헤더 파일
                #include <stdio.h>
                #include <stdlib.h>
                
                void* calcThread(void *param); // 스레드로 작동할 코드(함수)
                int sum = 0; // main 스레드와 calcThread가 공유하는 전역 변수
                
                int main() {
                        pthread_t tid; //  스레드의 id를 저장할 정수형 변수
                        pthread_attr_t attr; // 스레드 정보를 담을 구조체
                
                        pthread_attr_init(&attr); // 디폴트 값으로 attr 초기화
                        pthread_create(&tid, &attr, calcThread, "100"); // calcThread 스레드 생성
                        // 스레드가 생성된 수 커널에 의해 언젠가 스케줄되어 실행
                
                        pthread_join(tid, NULL); // tid 번호의 스레드 종료를 기다림
                        printf("calcThread 스레드가 종료하였습니다.\n");
                        printf("sum = %d\n", sum);
                }
                
                void* calcThread(void *param) { // param에 "100" 전달 받음
                        printf("calcThread 스레드가 실행을 시작합니다.\n");
                        int to =  atoi(param); // to = 100
                        int i;
                
                        for(i=1; i<=to; i++) // 1에서 to까지 합 계산
                                sum += i; // 전역 변수 sum에 저장
                }
                ```
                
            - 실행 과정
                
                <aside>
                💡
                
                1. 커널은 makethread를 실행시키기 위해 프로세스를 생성하고 PCB를 만든다. main스레드의 TCB를 생성하고, main()함수의 시작 주소와 여러 정보를 기록한다. 프로세스 주소 공간에는 main()과 calcThread() 코드가 적재되어있고 sum의 공간도 할당되어 있다.
                2. 커널은 현재 스케줄 가능한 TCB가 하나뿐이므로 main스레드의 TCB를 선택한다. 그러면 CPU는 TCB에 저장된 시작 주소에서 실행을 시작한다. main()에서 pthread_create()를 호출하면 calcThread()에서 실행을 시작하는 스레드, 즉 TCB가 생성된다. pthread_create()의 매개변수 100은 calcThread(void *param)의 매개변수로 전달된다. pthread_create()는 생성한 스레드의 번호를 tid에 넣고 스레드의 정보를 attr에 저장하고 리턴한다. 커널은 스케줄링을 통해 2개의 TCB중 하나를 선택해 실행한다. main과 calcThread 중 누가 먼저 실행될 지 아무도 모른다.
                3. main스레드가 실행되어 pthread_join(tid, ..)를 호출해 tid 번호의 calcThread스레드가 종료하길 기다린다. calcThread는 1-100 합을 계산하고 있다.
                4. calcThread가 최종 합을 구해 sum에 5050을 저장하고 종료하면 calcThread의 TCB가 제거되고 스레드가 사라진다. 코드가 사라지는 건 X, 코드는 그냥 적재된 코드일 뿐이다. main스레드는 pthread_join()에서 리턴해 sum값을 출력한다. main()이 종료하면 스레드의 TCB가 제거되고 스레드도 사라지며, 프로세스도 종료되어 사라진다.
                </aside>
                
            - 여기서 알 수 있는 스레드 개념들
                - 프로세스 생성 → 자동으로 main스레드 생성
                - main스레드는 main함수를 실행
                - 스레드 코드는 함수로 만들어짐
                - 스레드는 라이브러리 함수나 시스템 호출로 다른 스레드를 생성
                - 스레드마다 TCB 하나씩 생성
                - TCB에는 스레드의 시작 주소가 들어있고, 실행은 이 주소에서 시작된다
                - TCB가 하나의 스레드로 인식됨
        
    3. 스레드 주소 공간과 컨텍스트
        - 스레드 주소 공간 ?
            - **스레드가 실행 중에 사용하는 메모리 공간**으로 스레드의 코드,데이터,힙,스택 영역이며 이들은 **모두 프로세스의 주소 공간에 형성된다**
            - 스레드 사적 공간 : 스레드 스택, TLS(Thread Local Storage)
            - 스레드 공유 공간 : 프로세스의 코드, 데이터(TLS제외),힙 영역
        - 스레드 주소 공간
            - 스레드 코드 영역
            - 스레드 데이터 영역
                - TLS : 스레드가 자신만 사용할 수 있는 변수를 선언하는 공간
                - 프로세스에서 선언된 모든 전역변수들은 프로세스 내 모든 스레드에 의해 공유됨
            - 스레드 힙 영역 : 프로세스에 속한 모든 스레드들이 동적 할당받는 힙 공간으로 공유
            - 스레드 스택 영역 : 프로세스의 사용자 스택은 스레드가 생길 때마다 일부분이 스레드 스택으로 할당됨, 스레드 스택은 스레드의 사적 공간
        - 스레드 상태와 스레드 운용
            - 스레드 상태는 TCB에 저장된다
            - 스레드의 연산, 운용(스레드 생성,종료,조인,양보 ..)은 스레드를 구현하는 커널이나 스레드 라이브러리에 의해 이루어진다
            - 스레드 상태
                - Ready : 스레드가 스케줄을 기다림
                - Running : 스레드가 현재 CPU에 의해 실행되고 있음
                - Blocked : 스레드의 입출력 요청, 시스템호출로 커널에 의해 중단되어있음
                - Terminated : 스레드가 종료함
            - 스레드 운용
                - 스레드 생성
                - 스레드 종료
                    - 프로세스의 종료
                        - main스레드가 종료하는 경우
                        - 어떤 스레드가 exit() 하는경우 → 현재 스레드만 종료하려면 pthread_exit()
                        - 모든 스레드가 종료되는 경우
                    - 스레드 종료
                        - TCB가 시스템에서 제거되고 연결된 링크들이 해제, 매우 단순
                        - 스레드가 실행했던 함수 코드, 동적할당 받고 해제 안한 메모리는 프로새스 영역 내에 그대로 남아 있음
                - 스레드 조인
                    - 스레드가 다른 스레드의 종료를 기다림
                    - 스레드 번호(tid)만 알면 아무 스레드나 다른 스레드를 조인할 수 있음
                    - 주로, 부모 스레드가 자식 스레드를 생성해 작업시키고 완료를 기다릴 때 사용됨
                - 스레드 양보
                    - 실행중인 스레드가 다른 스레드에게 CPU를 양보하기 위해 스스로 실행 중단
                    - 양보한 스레드는 Ready상태로 준비 큐에 들어가고, 다른 Ready상태의 스레드 중 하나가 스케줄링되어 실행됨. 준비큐에 아무 스레드도 없으면 양보한 스레드가 다시 실행
        - 스레드 컨텍스트와 TCB
            - 스레드 컨텍스트
                - 스레드가 현재 실행중인 일체의 상황
                - CPU가 스레드를 실행하고 있을 때 CPU의 레지스터 값들
            - TCB (Thread Control Block)
                - 커널은 스레드를 실행단위로 관리하기 위해 TCB를 만들어 관리
                - CPU마다 레지스터 개수, 크기 다르므로 TCB에 저장되는 컨텍스트 크기도 CPU마다 다름
                - 커널 영역에 만들어지고 커널에 의해 관리됨
                - 커널이 실행 단위로 인식하는 스레드의 실체는 **TCB**
            - 준비 리스트, 블록 리스트
                - 커널의 스케줄러 코드는 준비 리스트에 있는 TCB 중 하나를 선택
                - 스레드가 입출력을 시행해 블록 상태가 되면 블록 리스트에 삽입됨
                - 스레드 관리 = TCB 관리
        - 스레드 컨텍스트 스위칭
            - 현재 CPU가 실행중인 스레드를 중단시키고 CPU에게 새 스레드를 실행시키는 과정, 작업 단위를 바꾸는 것
            - 현재 스레드의 CPU 레지스터 값을 TCB에 저장하고 선택된 스레드의 TCB의 컨텍스트를 CPU에 적재해 실행
            - 커널이 CPU 자원을 한 스레드에서 다른 스레드로 옮기는 작업
            - 언제 발생할까 ?
                - 스레드가 자발적으로 양보하는 경우 : yield 또는 sleep/wait ..등의 시스템 호출
                - 스레드가 I/O 작업 요청하는 시스템 호출해서 블록되는 경우
                - 타임슬라이스 소진한 경우 (ISR 내에서), Timer Interrupt
                - I/O 장치로부터 인터럽트 걸린 경우, I/O 완료!
                
                → **시스템 호출**을 처리하거나 **ISR 실행 도중** 커널 코드에서 이루어짐!
                
            - 스레드 스위칭 과정
                - CPU 레지스터 저장 및 복귀 → 커널 정보 수정 (TCB리스트를 조작)
        - 컨텍스트 스위칭 오버헤드
            - 동일한 프로세스 내에서 스레드 스위칭
                - 컨텍스트 저장, 복귀 시간
                - TCB 리스트 조작 시간 : 스레드의 TCB를 준비,블록 리스트로 옮기는 시간
                - 캐시 플러시 및 채우기 시간
            - 다른 프로세스의 스레드로 스위칭
                - 메모리 관련 오버헤드
                - 추가적인 캐시 오버헤드 : 현재 CPU 캐시에 담긴 모든 정보 무효화 해야해서 오래걸림
    
    1. 커널 레벨 스레드, 사용자 레벨 스레드
        - TCB를 생성하고 소유한 주체가 커널이냐 스레드 라이브러리냐에 따라 결정됨
        - 커널 레벨 스레드
            - 커널 코드에 의해 만들어져, 커널에 의해 그 존재가 인지되고, 커널에 의해 스케줄링되는 스레드
            - 커널에 만들어진 TCB들을 대상으로 커널에 의해 스케줄링되는 스레드
            - 시스템 호출을 통해서만 이 기능을 활용할 수 있음
            - 커널 레벨 스레드의 코드와 데이터는 사용자 공간에 있을수도, 커널 공간에 있을 수도 있음
            - 순수 커널 레벨 스레드 (pure kernel level thread) : 특별히 부팅할 때부터 커널 공간에서 실행되고 커널을 돕는 목적으로 만들어지는 스레드
        - 사용자 레벨 스레드
            - 스레드 라이브러리에 의해 사용자 공간에 생성되고, 관리되고, 스케줄되는 스레드
            - 사용자 레벨 스레드는 사용자 공간에 생성,관리됨 → 존재가 커널에 전혀 알려지지 않음
            - 3개의 PCB가 만들어져 있고, 커널은 3개의 프로세스가 실행되고 있다고 알고 있다. 현재 PCB3가 선택되어 실행되고 있다면 프로세스3은 스레드 라이브러리를 이용해 3개의 사용자 레벨 스레드를 생성했고 U-TCB 3개를 생성/관리한다. 자체에 내장한 스케줄러 코드를 이용해 이 중 하나를 선택해 스레드 코드를 실행한다. 이 때 커널은 사용자 스레드의 존재에 대해 모른다.
            - 커널은 프로세스 하나를 하나의 스레드로 인식, 사용자가 만들어놓은 3개의 사용자 스레드의 존재와 어떤 사용자 스레드가 실행되고 있는지 전혀 모름
        - 비교
            
            
            |  | 사용자 스레드 | 커널 스레드 |
            | --- | --- | --- |
            | 정의 | 스레드 라이브러리에 의해 스케줄 | 커널에 의해 스케줄 |
            | 스레드 스위칭 | 사용자 모드에서, 스레드 라이브러리에 의해 | 커널 모드에서, 커널에 의해 |
            | 컨텍스트 스위칭 속도 | 빠름 | 느림 |
            | 멀티스레드 APP | 시스템호출X→작성 쉽고, 생성속도 빠름 | 시스템호출O→ 속도느림 |
            | 이식성 | 높음 | 시스템 호출이 운영체제마다 달라 낮음 |
            | 병렬성 | 멀티코어CPU에서 병렬처리 X | 서로 다른 CPU나 서로 다른 코어에서 병렬 실행 가능 |
            | 병렬성의 종류 | 동시성, Concurrency | 병렬성, Parallelism |
            | 블록킹 | 하나의 사용자 스레드가 blocked 되면 모든 사용자 스레드가 중단 | 해당 스레드만 중단 |
            | 커널 부담 | X | 커널코드 실행시간 증가, 시스템 전체에 부담 |
            | 스레드 동기화 | 스레드 라이브러리에 의해 | 시스템 호출을 통해 커널에 의해 |
            | 최근 경향 | 멀티코어 CPU에 부적합, 줄고있음 | 높은 병렬성, 많이 사용됨 |
    2. 사용자 스레드와 커널 스레드 매핑
        - N:1 매핑
            - 모든 사용자 스레드를 하나의 커널 스레드로 매핑
            - N개의 U-TCB를 1개의 TCB에 매핑
            - N:1 매핑을 사용하는 운영체제 → 기본적으로 단일 스레드 프로세스로 다룸
            - N개의 U-TCB가 1개의 TCB에 묶여있기 때문에 N개가 실행되려면 그 TCB가 스케줄링 되야함
            - 실행하다가 중지하고 다른 TCB를 스케줄링하면 실행중이던 U-TCB의 컨텍스트를 TCB에 저장해두고 컨텍스트 스위칭이 일어남
            - 장점
                - 속도가 빠름 : 커널 진입 X, 스레드 라이브러리에 의해 사용자 공간에서 이루어지기 때문
            - 단점
                - 사용자 스레드 중 하나에게만 CPU 코어 할당 → 병렬성 X
                - 스레드 하나 실행하다가 블록 → 해당 TCB가 다시 스케줄 될 때까지 프로그램 실행 중단
        - 1:1 매핑 (오늘날 사용)
            - 사용자 스레드 하나당 TCB 하나씩 연계
            - 서로 다른 사용자 스레드가 서로 다른 코어에서 동시에 실행됨
            - 장점
                - 개념 단순, 구현 쉬움
                - 높은 병렬성
                - 응용 프로그램 전체가 중단되는 일 X
            - 단점
                - 운영체제 비용 부담이 큼
                - 커널에 TCB를 비롯한 많은 구조체 생성
                - 커널모드 진입 횟수 많아짐
                - 모든 스레드를 커널이 스케줄 → 시간 부담, 커널 부담이 커짐
        - N:M 매핑
            - N개의 사용자 스레드를 M개의 커널 스레드와 매핑
            - 스레드 라이브러리가 커널에게 커널 스레드 만들라고 system call
            - 구현 복잡해 현재 거의 사용 X
- chap05 : CPU 스케줄링
    1. 개요
        - CPU 스케줄링 : 준비 상태의 스레드 중 하나를 선택하는 스레드 스케줄링
        - CPU burst, I/O burst
            - CPU burst : 프로그램의 실행 과정에서 CPU가 코드르 집중적으로 실행하는 상황
            - I/O burst : I/O장치에 의해 입출력이 이루어지는 상황
            
            → 일반적으로 응용프로그램에는 둘이 적절히 섞여있음
            
            → CPU burst가 많으면 CPU 집중 프로세스, I/O burst가 많으면 I/O 집중 프로세스 (intensive)
            
        - CPU 스케줄링의 기준
            - CPU 활용률 : 전체 가동 시간에 대한 CPU 사용 시간에 대한 비율
            - 처리율, 공평성, 응답시간, 대기시간, 소요시간
            - 시스템 정책 우선 : 시스템의 정책이 실시간 시스템인 경우 → 데드라인 맞춰서 스케줄링
            - 자원 활용률
        - 타임 슬라이스 : 스레드가 CPU 사용을 보장받는 시간, 커널이 CPU 스케줄링을 하는 주기 시간
        
    2. CPU 스케줄링
        - CPU 스케줄링을 하는 경우
            - 스레드가 I/O 요청하는 시스템 호출 실행해서 Blocked 상태가 될 때
            - 스레드가 자발적으로 CPU를 반환할 때
            - 스레드에게 할당된 타임슬라이스 소진해서 타이머 인터럽트 발생할 때
            - 현재 실행중인 스레드보다 더 높은 순위의 스레드가 요청한 입출력이 완료되어 I/O 인터럽트가 발생할 때
        - 스케줄링을 담당하는 별도의 커널 프로세스,스레드가 있는가 ?
            - Xxx, 시스템호출이나 ISR에 의해 호출되는 함수 형태로 존재
        - CPU 스케줄링이 실행되는 자세한 시점은 ?
            - 시스템 호출이나 ISR의 마지막 과정에서 스케줄링이 필요할 때
        - 디스패처 코드
            - 스케줄러 코드에 의해 선택된 스레드를 CPU가 실행하도록 하는 커널 코드의 일부분
            
            → CPU 스케줄링 (스케줄러 코드 실행) + 디스패치 (디스패처 코드 실행) → 이 시간 동안은 스케줄링 오버헤드, CPU는 아무 작업도 할 수 없기 때문에 가능한 짧게 작성해야함
            
        - **스케줄링 타입 : 선점 스케줄링, 비선점 스케줄링 ****
            - 실행 중인 스레드를 강제로 중단시키는지 여부에 따라 나뉨
            - 비선점 스케줄링, non-preemptive scheduling
                - 일단 스레드가 CPU를 할당받아서 실행 시작하면 완료되거나 CPU를 더이상 사용할 수 없는 상황(I/O로 인한 블록, yield(), 스레드 종료 ..)이 될 때까지 스레드를 강제로 중단시키지 않는다
                - 실시간 시스템과 같은 현재 스레드가 정말 중요한 일을 하고있을 수도 .. (은행같은) 이럴 때는 비선점 스케줄링을 함
            - 선점 스케줄링, preemptive scheduling
                - 여러 상황상 이유(타임 슬라이스 소진, 인터럽트/시스템호출 종료 시점에서 더 높은 우선순위의 스레드가 대기상태에 있을 때 ..)로 인해 현재 실행 중인 스레드를 강제로 중단시켜 준비 리스트로 이동시키고 스케줄링한다
                - 대부분의 운영체제는 선점 스케줄링을 함
        - 기아, 에이징
            - 기아 : 스레드가 스케줄링 과정에서 선택되지 못한 채 오랜 시간동안 준비리스트에 있는 상황
            - 에이징 : 스레드가 준비리스트에 머무르는 시간에 비례해 우선순위를 높여주는 기법, 언젠가는 높은 우선순위로 도달하는 것이 보장되기 때문에 기아를 해결할 수 있음
            
    3. CPU 스케줄링 알고리즘
        - FCFS, First Come First Served
            - 알고리즘 : 큐에 먼저 도착한 스레드를 먼저 스케줄링
            - 비선점 스케줄링
            - 스레드 우선순위 X
            - 기아 X
            - 성능 이슈 : 긴 CPU burst를 실행하는 스레드가 양도할 때 까지 뒤에 스레드들이 오래 대기해 시스템 전체가 느려지는 호위효과 (Convoy Effect) 발생 가능성
            - 처리율은 낮지만 단순하고 구현 용이
        - SJF, Shortest Job First
            - 알고리즘
                - 실행시간이 가장 짧은 스레드를 먼저 실행시켜 스레드들의 평균 대기 시간을 줄이는 게 목적
                - 준비 큐에서 예상 실행 시간이 가장 짧은 스레드를 우선 선택 → 근데 실행시간은 예측 불가능하기 때문에 비현실적
            - 비선점 스케줄링
            - 스레드 우선순위 X
            - 기아 발생 가능 : 짧은 실행시간의 스레드가 계속 큐에 도착 → 긴 실행시간 스레드에 기아 발생
            - 평균 대기 시간 최소화, 비현실적
        - SRTF, Shortest Remaining Time First
            - 알고리즘 : SJF의 선점 스케줄링 버전, 남은 실행 시간이 가장 짧은 스레드를 우선 스케줄링
            - 선점 스케줄링
            - 스레드 우선순위 X
            - 기아 발생 가능
            - 평균 대기 시간 최소화, 비현실적
        - RR, Round Robin
            - 알고리즘
                - 스레드들에게 공평한 실행 기회 → 타임슬라이스 주기로 돌아가면서 선택
                - 커널은 한번에 한 스레드에게 타임슬라이스의 시간만큼만 CPU 사용하도록 함
            - 선점 스케줄링 : 타임슬라이스 지나면 강제 중단시켜 큐 끝에 다시 삽입
            - 스레드 우선순위 X
            - 기아 X : 타임슬라이스만큼 돌아가면서 실행, 일정 시간 후에는 반드시 실행 기회를 얻음
            - 성능 이슈
                - 공평함, 기아 없음, 구현 쉬움
                - 잦은 스케줄링 → 스케줄링과 컨텍스트 스위칭에 소요되는 시간이 길다
                - 타임슬라이스 작을수록 스케줄링 횟수 증가하므로 성능 저하.. 스케줄링 오버헤드 증가
            - RR은 FCFS와 SJF의 극단성에 균형을 취함
                - 타임슬라이스 크면 FCFS에 가까워짐, 작으면 SJF/SRTF에 가까워짐
        - Priority
            - 알고리즘
                - 철저한 우선순위 기반의 알고리즘
                - 스레드마다 고정 우선순위 → 큐에서 가장 높은 우선순위의 스레드를 선택
            - 선점, 비선점 스케줄링 모두 가능
                - 선점 스케줄링 (Preemptive Fixed Priority) : 더 높은 순위의 스레드가 도착할 때 현재 스레드 중단시키고 스케줄링
                - 비선점 스케줄링 (Non-Preemptive Fixed Priority : 현재 실행중인 스레드가 종료한 후 스케줄링
            - 스레드 우선순위 O : 스레드마다 고정 우선순위
            - 기아 발생 가능 : 계속 높은 순위의 스레드가 큐에 도착 → 낮은 순위의 스레드에 기아 발생, 에이징으로 해결할 수 있음
            - 성능 이슈
                - 우선순위 높은 스레드일수록 대기시간, 응답시간 짧음
                - 실시간 시스템에서 주로 사용
        - MLQ, Multi Level Queue
            - 알고리즘
                - 스레드들을 N개의 우선순위 레벨로 구분하고 레벨이 높은 스레드를 우선 스케줄링
                - 스레드는 도착한 순서대로 큐에 삽입, 다른 큐로 이동 불가
                - 가장 높은 레벨의 큐에서 맨 앞에 있는 스레드 선택, 높은 레벨의 큐가 비어있을 때 그 아래 레벨의 큐에서 스레드 선택
            - 선점, 비선점 스케줄링 모두 가능
                - 선점 스케줄링 : 실행 중 더 높은 레벨의 큐에 스레드 도착하면 현재 스레드 중단
                - 비선점 스케줄링 : 스레드가 종료할 때 스케줄링
            - 스레드 우선순위 O : 고정 우선순위, N 레벨 중 하나
            - 기아 발생 가능 : 지속적으로 높은 레벨의 큐에 스레드가 도착하는 경우 발생 가능
            - 성능 이슈
                - 높은 레벨 스레드들의 대기시간, 응답시간 짧음
                - 낮은 레벨의 큐에 있는 스레드가 높은 레벨의 큐로 이동 X → 기아 발생 가능성
            - 활용 사례
                - 시스템 전체 스레드를 → 백그라운드 스레드 / 포그라운드 스레드
                - 시스템 스레드 / 대화식 스레드 / 배치 스레드
                - 교수 / 교직원 / 대학원생 / 학부생
                - 메시징 서버 → 매우 긴급 / 긴급 / 보통 / 낮음
        - MLFQ, Multi-Level Feedback Queue
            - 알고리즘
                - CPU burst가 짧은 스레드, I/O 작업이 많은 스레드, 대화식 스레드를 우선 실행 → 스레드의 평균 대기시간을 줄여 사용자의 응답 시간 감소, 기아 발생하지 않게 함
                - n개의 레벨 큐
                    - 우선순위(레벨)로 구분된 n개의 큐를 둠
                    - 각 큐는 CPU burst 시간에 관련 → 낮은 레벨의 큐일수록 타임슬라이스가 크게 설정
                    - 실행중인 스레드의 CPU-burst가 큐의 타임슬라이스 넘어가면 강제 중단되어 아래 레벨의 큐로 이동, 타임슬라이스를 넘어가기 전에 CPU-burst가 끝나는 스레드는 동일한 큐에 다시 삽입됨
                - 도착하는 스레드는 가장 높은 레벨 큐에 삽입
                - 가장 높은 레벨 큐에서 스레드 선택해 실행, 큐가 비었으면 아래 레벨에서 선택
                - 스레드가 I/O를 요청하면 해당 큐에서 나오지만, 끝나면 동일한 큐로 다시 삽입
                - 큐에서 대기하는 시간이 길어지면 기아를 막기 위해 한 레벨 위의 큐로 이동
                - 최하위 레벨의 큐는 주로 FCFS, 긴 타임 슬라이스의 RR로 스케줄링됨
            - 선점 스케줄링 : CPU burst가 큐의 타임슬라이스 초과하면 강제 중단
            - 스레드 우선순위 X
            - 기아 X : 에이징 기법 사용, 운영체제마다 다름
            - 성능 이슈
                - CPU burst가 짧은 스레드, I/O 작업이 많은 스레드, 대화식 스레드를 우선 스케줄링 → 스레드의 평균 대기시간을 줄임
                - 기아를 막을 수 있다
                - 큐 개수, 타임슬라이스 값 조절 → 대상 시스템에 적합하게 구현할 수 있음, 유연성 뛰어남
                - 알고리즘 복잡해서 CPU 오버헤드가 증가
        
        1. 멀티 코어 CPU에서의 스케줄링
            - 싱글 코어에서 사용하던걸 멀티 코어에 그대로 적용하면 나타나는 문제, 해결방법
                - 컨텍스트 스위칭 후 오버헤드 증가 (다른 코어에 TCB 할당할 때, 코어1→코어3)
                    - CPU 스케줄러가 최근에 실행된 적이 있는 스레드 중 하나를 선택하면, 캐시를 다시 채우는 과정이 줄어들 수 있다
                    - 코어 친화성으로 해결
                        - 코어 친화성 (Core Affinity) : 프로세스나 스레드가 특정 CPU에서만 실행되도록
                        - 코어마다 스레드 큐를 두고, 한 코어에서 실행이 중단된 스레드를 다시 동일한 큐에
                        - 사용자가 개별 스레드마다 다른 코어에 친화성을 둘 수도 있지만, 이 일에 있어서는 운영체제가 사용자보다 똑똑하기 때문에 운영체제한테 맡기는게 나음
                - 코어 별 부하 불균형 : 스레드가 몰린 코어에서 실행되는 스레드들은 대기/처리시간 길어짐
                    - 부하 균등화(Load Balancing)로 해결
                        - Push Migration : 시스템에 스레드 큐를 감시하는 별도의 감시 스레드를 두고 다른 스레드 큐로부터 스레드를 강제로 옮기는 기법 → 코어마다 처리하는 스레드의 개수를 균등하게 유지
                        - Pull Migration : 코어가 처리할 스레드가 없게 될 때마다 다른 코어의 스레드 큐에서 스레드를 가져와 자신의 스레드 큐에 넣고 실행하는 기법
            
- chap06 : 스레드 동기화
    1. 스레드 동기화의 필요성
        - 공유 데이터에 대한 다수 스레드의 동시 접근 → 공유 데이터 훼손 가능성
        - 스레드 동기화 : 다수의 스레드가 공유 데이터에 동시에 접근할 때, 한 스레드가 공유 데이터 사용을 마칠 때까지 다른 스레드가 접근하지 못하도록 공유 데이터를 보호하며 스레드의 실행을 제어하는 기법
        - 공유 데이터에 대한 멀티스레드 동시 접근 문제
            - 스레드 T1, T2가 공유 변수 sum을 동시에 10 증가시키는 모델
                
                `sum = sum + 10`
                
                이 코드를 기계 명령으로 번역하면 -
                
                ```cpp
                mov ax, sum // sum 변수 값을 읽어 ax 레지스터에 저장
                add ax, 10 // ax 레지스터의 값을 10 증가
                mov sum, ax // ax 레지스터의 값을 sum 변수에 저장
                ```
                
                1) T1이 sum 변수 값을 읽은 후 중단됨
                
                2) T2가 실행되어 sum 변수에 60 기록 (원래 50이었음)
                
                3) T1이 실행되어 sum 변수에 60 기록 → 70이 되어야 하는데 잘못된 결과 발생!
                
                > **CPU는 메모리에서 계산 X, 반드시 레지스터에서 값을 읽어와서 계산!**
                > 
            - 문제점 : 여러 스레드가 공유 데이터에 동시 접근할 때 공유 데이터가 훼손될 수 있다 → 사용자의 멀티스레드 프로그램, 커널코드에서 자주 발생, 다중 코어에서 주의
            - 해결책 : 스레드 동기화, 한 스레드가 공유 데이터에 대한 접근을 마칠 때 까지 다른 스레드가 접근하지 못하도록 제어
        - **임계구역과 상호배제 ****
            - 임계구역 (critical section) : 사용자가 작성한 프로그램 중 공유 데이터에 접근하는 코드 블록
            - 상호배제 (mutual exclusion) : 임계구역에 먼저 진입한 스레드가 임계구역의 실행을 끝낼 때까지 다른 스레드가 진입하지 못하도록 보장하는 기법
            
    2. 상호배제, Mutual Exclusion
        - 임계구역 전후에 상호배제 코드 작성, 진입코드(entry코드)와 진출코드(exit코드)
        - 코드 종류
            - 일반 코드 (non-critical code)
            - 임계구역 진입코드 (entry code)
                - 임계구역에 진입하기 전 필요한 코드블록
                - 현재 임계구역을 이미 실행중인 스레드가 있는지 검사하고 없는 경우 다른 스레드가 들어오지 못하도록 조치
                - 이미 진입한 스레드가 있으면 그 스레드가 exit 할때까지 대기시킴
            - 임계구역 진출코드 (exit code)
                - 스레드가 임계구역 실행을 마칠 때 실행되어야 하는 코드블록
                - entry 코드에서 취한 조치 해제
            - 임계구역 코드 (critical code)
                - 한 번에 한 스레드만 실행되도록 보장되어야 하는 프로그램 부분
                - 임계구역은 짧을 수록 좋다
        - 상호배제 구현
            - 임계구역에 오직 한 스레드만 들어가게 하는 방책
            - 방법 2가지 → 소프트웨어적 방법, 하드웨어적 방법
            - 하드웨어적 방법 2가지
                - 인터럽트 서비스 금지
                    - entry코드에서 인터럽트 서비스를 금지하고 exit코드에서 인터럽트 서비스 허용
                    - 임계구역 실행하는 동안 인터럽트 X → 스레드 선점 (preemptive) 불가
                    - cli (entry코드에서 인터럽트 서비스 금지 명령, clear interrupt flag)
                    - sti (exit코드에서 인터럽트 서비스 허용 명령, set interrupt flag)
                    
                    → 임계구역에 진입하기 전에 인터럽트 서비스를 중지시켜 상호배제 성공
                    
                    - 문제점
                        - 임계구역을 실행하는 동안 모든 인터럽트 무시됨, 매우 중요한 인터럽트 들어올 수도 있잖아 ..
                        - 다중 CPU를 가진 시스템에서 한 스레드가 다른 코어의 인터럽트 서비스까지 금지시키지 못함
                - 원자명령 사용
                    - 원자명령 (atomic instruction) : 상호배제를 위해 만들어진 CPU 명령
                    - 원자명령 없이 lock변수 이용
                        
                        ```cpp
                        li:
                        mov ax, lock // lock 변수 값을 ax 레지스터로 읽어옴
                        mov lock, 1 // 다른 스레드가 임계구역 못 들어오게 잠금 lock=1
                        cmp ax, 0 // lock 값이 0이었는지 검사, 이전 lock변수가 0이었는지 비교
                        jne l1 // 이전 명령에서 비교한 값이 같으면 임계구역 진입, 같지 않으면 l1으로
                        -------------
                        임계 구역
                        -------------
                        mov lock, 0 // lock 변수에 0 저장
                        ```
                        
                        → lock 값이 1이었다면 임계구역에 들어가있는 스레드가 있다는 뜻이므로 임계구역에 들어가선 안된다. 그래서 lock 값이 0이 될때까지 비교하면서 상호배제를 구현한다
                        
                        - 여기서 만약, T1이 실행하다가 lock변수에 1을 쓰지 못한 상태로 중단되고, T2가 실행하다가 lock변수에 1을 쓰고 임계구역 실행하다가 중단되었다면?
                            
                            → T1이 다시 스케줄되어 lock에 1을 쓰고 ax값에는 이전 컨텍스트가 복귀되어 0인 상태이므로 cmp ax, 0에서 통과해 임계구역에 진입하게 된다. 상호배제 실패!!
                            
                    - 왜 실패했을까?
                        - lock 변수 값을 읽어들이는 명령과 lock변수를 1로 바꾸는 명령 사이에 컨텍스트 스위칭이 발생할 때 문제가 발생한다. 이 두 명령이 하나의 단위로 실행되지 않아서
                        - 해결방법 : 두 명령을 하나의 명령으로 만든다 (=원자명령,TSL명령)
                    - 원자명령으로 해결
                        
                        mov ax, lock  + mov lock, 1    →   **TSL ax, lock**
                        
                        (* TSL : Test and Set Lock)
                        
            
    3. 멀티스레드 동기화 기법
        - 동기화 프리미티브 (Synchronization Primitive) : 동기화 기법들은 스레드 라이브러리나 시스템 호출에 의해 제공되고 이들은 스레드 동기화를 위해 멀티스레드 응용프로그램에서 반드시 사용되어야 한다
        - lock 방식 : 뮤텍스, mutex
            - 잠김/열림 (locked/unlocked) 중 한 상태를 가지는 락 변수를 이용해 한 스레드만 임계구역에 진입시키고 다른 스레드들을 큐에 대기시키는 기법
            - 변수 : 락 변수
            - 연산
                - lock
                    - 임계구역에 들어가기 전 실행하는 entry-code
                    - 락이 잠겨있으면 현재 스레드를 블록상태로 만들고 대기 큐에 삽입한다
                    - 락이 열려있으면 임계구역에 진입하게 한다
                - unlock
                    - 임계구역에서 나올때 실행하는 exit-code
                    - 락을 열림 상태로 바꾸고 대기 큐에 있는 스레드 하나를 깨워 Ready상태로
            - 큐 : 대기 큐 (wait queue)
            - 락이 잠겨있는 경우 락이 풀릴 때 까지 스레드가 블록 상태로 대기 큐에서 잠을 자기 때문에 블록킹 락(blocking lock)이나 수면 대기 락(sleeping-waiting lock)으로 불림
            - 특징
                - 임계구역의 실행 시간이 짧은 경우, 비효율적
                    - 락이 잠겨 있는 시간 < 자고 깨는데 걸리는 시간
                    - 컨텍스트 스위칭 2번
            - 코드
                
                ```cpp
                #include <stdio.h>
                #include <pthread.h>
                
                int sum = 0; // 두 스레드가 공유하는 변수
                pthread_mutex_t lock; // 뮤텍스락 변수 선언
                
                void* worker(void* arg) { // 스레드 코드
                  printf("%s 시작 \t %d\n", (char*)arg, sum);
                
                  for(int i=0; i<1000000; i++) {
                  pthread_mutex_lock(&lock); // entry 코드. 뮤텍스 락 잠그기
                  sum = sum + 10; // 임계구역 코드
                  pthread_mutex_unlock(&lock); // exit 코드. 뮤텍스 락 열기
                  }
                  printf("%s 끝 \t %d\n", (char*)arg, sum);
                }
                
                int main() {
                  char *name[] = {"황기태", "이찬수"};
                  pthread_t tid[2];
                pthread_attr_t attr[2]; // 스레드 정보를 담을 구조체
                
                pthread_attr_init(&attr[0]); // 디폴트 속성으로 초기화
                pthread_attr_init(&attr[1]); // 디폴트 속성으로 초기화
                
                  pthread_mutex_init(&lock, NULL); // 뮤텍스락 변수 lock 초기화
                  
                  // 스레드 생성
                  pthread_create(&tid[0], &attr[0], worker, name[0]);  
                  pthread_create(&tid[1], &attr[1], worker, name[1]); 
                
                  pthread_join(tid[0], NULL); // 스레드 종료 대기
                  pthread_join(tid[1], NULL);
                
                  printf("최종 sum = %d\n", sum);
                
                  pthread_mutex_destroy(&lock); // 뮤텍스락 lock 사용 끝
                
                  return 0;
                }
                ```
                
            
            - worker()를 다르게 작성하면 ?
                
                ```cpp
                void* worker(void* arg) { // 스레드 코드
                  printf("%s 시작 \t %d\n", (char*)arg, sum);
                  pthread_mutex_lock(&lock); // lock
                  for(int i=0; i<1000000; i++) { // 임계구역
                  sum += 10;
                  }
                  pthread_mutex_unlock(&lock); // unlock
                  printf("%s 끝 \t %d\n", (char*)arg, sum);
                }
                ```
                
                → 첫번째 worker는 락을 걸고 풀기를 1000000번 하기 때문에 실행 속도가 느리다. 두번째 코드처럼 해도 먼저 락을 건 스레드가 sum을 더하기 시작하면 다른 스레드는 대기해야 하기 때문에 상호배제는 둘 다 잘 되지만 실행 속도가 현저히 차이난다 !
                
        - lock 방식 : 스핀락, spinlock
            - mutex와 같이 lock을 기반으로 하지만, 스핀락은 대기큐가 없다
            - 변수 : 락 변수
            - 연산
                - lock
                    - 락이 잠겨 있으면 무한 루프를 돌면서 락이 풀릴 때까지 검사한다. 결국 그러다 타임 슬라이스가 소진되면 스레드는 컨텍스트 스위칭되고, 다시 스케줄되면 다시 락이 풀릴 때까지 검사
                    - 공격적인 뮤텍스 (aggressive mutex)
                - unlock : 락을 열림으로 변경
            - 스핀락은 바쁜 대기 락 (busyh-waiting lock) 이라고도 함
            - 특징
                - 뮤텍스 기법의 바쁜 대기 모형, non-blocking model
                - 단일 CPU를 가진 운영체제에서 매우 비효율적 → lock 연산이 락이 열렸는지 잠겼는지 계속 검사하면서 CPU를 소모함
                - 멀티코어 CPU에서 락을 경쟁하는 스레드들을 서로 다른 코어에서 실행시키면 매우 효과적
                - 임계구역 코드가 짧아서 락이 빨리는 응용에 매우 효과적
                - 기아 발생 가능성
                - 리눅스 커널은 스레드 동기화의 기본 기법으로 스핀락 사용
            - 코드
                
                ```cpp
                #include <stdio.h>
                #include <pthread.h>
                
                int sum = 0; // 두 스레드가 공유하는 변수
                pthread_spinlock_t lock; // 스핀락 변수 선언
                
                void* worker(void* arg) { // 스레드 코드
                  printf("%s 시작 \t %d\n＂, (char*)arg, sum);
                  for(int i=0; i<1000000; i++) {
                  pthread_spin_lock(&lock); // entry 코드
                  sum = sum + 10; // 임계구역 코드
                  pthread_spin_unlock(&lock); // exit 코드
                  }
                  printf("%s 끝 \t %d\n", (char*)arg, sum);
                }
                
                int main() {
                  char *name[] = {"황기태", "이찬수"};
                  pthread_t tid[2]; // 두 스레드의 ID를 저장할 배열
                
                  pthread_attr_t attr[2]; // 스레드 정보를 담을 구조체
                
                  pthread_attr_init(&attr[0]); // 디폴트 속성으로 초기화
                  pthread_attr_init(&attr[1]); // 디폴트 속성으로 초기화
                
                  // lock을 한 프로세스에 속한 스레드만이 공유하는 변수로 선언
                  pthread_spin_init(&lock, PTHREAD_PROCESS_PRIVATE); 
                
                  // 스레드 생성
                  pthread_create(&tid[0], &attr[0], worker, name[0]); 
                  pthread_create(&tid[1], &attr[1], worker, name[1]); 
                
                  pthread_join(tid[0], NULL); // 스레드 종료 대기
                  pthread_join(tid[1], NULL);
                  printf("최종 sum = %d\n", sum); 
                
                  pthread_spin_destroy(&lock);
                
                  return 0;
                }
                ```
                
        
        - 하이브리드 뮤텍스, hybrid mutex
            - 스핀락 + 뮤텍스
            - 처음에는 스핀락처럼 동작하다가 일정시간이 지날때까지 락을 획득하지 못하면 뮤텍스처럼 작동해 스레드를 블록 상태로 만들어 대기 큐에 넣고 대기시킴
            - 적응형 뮤텍스 (adaptive mutex), 적응형 스핀락 (adaptive spinlock)으로 불림
            - 오늘날 커널에서 많이 사용
        - 스레드 동기화는 사용자 응용 프로그램, 커널 코드 모두에게 필요 ?
            - 사용자 공간에 있는 공유 자원과 임계구역 코드
            - 커널 공간에 있는 커널 자원과 임계구역 코드
            
            → 각각 배타적으로 스레드가 접근하도록 동기화되어야 한다.
            
        - 뮤텍스 VS 스핀락
            
            
            |  | 뮤텍스 | 스핀락 |
            | --- | --- | --- |
            | 대기 큐 | O | X |
            | 효율 | 락이 잠기는 시간이 긴 경우 | 락이 잠기는 시간이 짧은 경우 |
            | 블록 가능 여부 | 락이 잠겨 있으면 블록됨 (blocking) | 락이 잠겨 있어도 블록되지 않고 계속 검사 (non-blocking) |
            | lock 연산비용 | 저비용 | CPU 계속 소모 → 고비용 |
            | 하드웨어 관련 | 단일 CPU에 적합 | 멀티코어 CPU에 적합 |
            | 주 사용처 | 사용자 응용 프로그램 | 커널 코드, ISR |
        - wait-signal 방식 : 세마포, Semaphore
            - n개의 자원을 다수의 스레드가 **공유**하여 사용하도록 돕는 **자원 관리 기법**
            - 자원 : n개
            - 대기 큐 : 자원을 할당받지 못한 스레드가 잠자는 곳
            - counter 변수
                - 사용가능한 자원의 개수를 나타내는 정수형 변수로 자원의 개수 n으로 초기화
                - counter 변수가 음수이면 자원을 기다리는 스레드의 개수를 나타냄
                - counter 변수를 구현하는 방법에 따라 사용가능한 자원이 없을 때 counter 변수를 계속 0으로 유지하기도 함
            - P / V 연산 (wait / signal 연산)
                - 두 연산은 원자적으로 수행됨
                - P 연산
                    - 스레드에게 자원 사용을 허가하는 과정
                    - counter 변수를 1 감소시킴 (고객이 화장실에 들어갔으니까 빈 방 -1)
                - V 연산
                    - 스레드가 자원 사용이 끝났음을 세마포에게 알리는 과정
                    - counter 변수를 1 증가시킴 (고객이 화장실에서 나왔으니까 빈 방 +1)
                - 자원을 할당받지 못하는 스레드를 다루는 방법에 따라 2가지 종류로 -
                    - 수면 대기 (sleep-wait) 세마포
                        - P 연산 : 자원 사용을 허가받지 못한 스레드를 대기 큐에서 잠을 재우고
                        - V 연산 : 사용 가능한 자원이 생기면 스레드를 깨워 자원 사용을 허락
                    - 바쁜 대기 (busy-waiting) 세마포
                        - P 연산 : 가용 자원이 생길 때까지 무한 루프를 돌면서 검사, V 연산에 의해 가용자원이 생기면 → 자원 획득 !
                        - V 연산 : P 연산에 가용 자원이 생겼다고 말해줌
                        - 대기 큐 X
            - counter 변수는 P, V 연산에 의해 공유되는 변수이므로 counter에 대한 접근은 원자적으로 처리되도록 구현, 여러 스레드가 동시에 P 연산 X
            - counter 변수를 세마포 변수라고도 함
            - 코드
            
            ```cpp
            #include <stdio.h>
            #include <pthread.h>
            #include <semaphore.h>
            #include <unistd.h>
            
            sem_t toiletsem; // POSIX 세마포 구조체로 모든 스레드에 의해 공유
            
            void* guestThread(void* arg) { // 고객의 행동을 묘사하는 스레드 코드
                int cnt = -1;
            
                sem_wait(&toiletsem); // P 연산, 자원 사용 요청. 
            													//세마포의 counter 값 1 감소
                // 세마포의 counter 을 cnt 변수로 읽어오기
                sem_getvalue(&toiletsem, &cnt); 
                printf("고객%s 화장실에 들어간다... 세마포 counter = %d\n", (char*)arg, cnt);
                sleep(1); // 1초 동안 화장실을 사용한다.
                sem_post(&toiletsem); // V 연산. 화장실 사용을 끝냈음을 알림
                sem_getvalue(&toiletsem, &cnt); 
                printf("고객%s 화장실에서 나온다.세마포 counter = %d\n", (char*)arg, cnt);
            }
            
            #define NO 0                 // 자식 프로세스와 세마포 공유하지 않음
            #define MAX_COUNTER 3 // 자원의 개수, 동시에 들어갈 수 있는 스레드의 개수
            
            int main() {
                int counter = -1;
                char *name[] = {"1", "2", "3", "4", "5" };
                pthread_t t[5]; // 스레드 구조체
            
                // 세마포 초기화 : MAX_COUNTER 명이 동시에 사용
            		// 자원의 개수를 구조체에 초기화
                sem_init(&toiletsem, NO, MAX_COUNTER);
                // 세마포의 현재 counter 값 읽기
                sem_getvalue(&toiletsem, &counter); 
                printf("세마포 counter = %d\n", counter);
            
                // 5명의 고객(스레드) >생성
                for(int i=0; i<5; i++) 
            			pthread_create(&t[i], NULL, guestThread, (void*)name[i]); 
            
                for(int i=0; i<5; i++) 
            			pthread_join(t[i],NULL); // 모든 고객이 소멸할 때까지 대기
            
                
                sem_getvalue(&toiletsem, &counter); 
                printf("세마포 counter = %d\n", counter);
                sem_destroy(&toiletsem); // 세마포 기능 소멸
            
                return 0;
            }
            ```
            
            → 이 코드에서 sem_wait() 대신 sem_trywait() 이용하면 ? 
            
            - `sem_wait(&toiletsem); → **while(sem_trywait(&toiletsem));**`
                - 바쁜 대기 세마포
                - sem_trywait() 함수는 toiletsem 세마포를 검사하여 사용가능한 자원이 없다면 바로 -1을 리턴하고 사용가능한 자원이 있으면 0 리턴
                - 사용가능한 자원이 생길 때까지 무한루프를 도는 코드
                
            
            > busy-waiting, busy-looping, spinning
            > 
            > - 셋 다 바쁜 대기라고 해석되는 표현들
            > - 스레드가 어떤 조건에 대해 true가 될 때까지 반복 조사하면서 기다리는 기법
            > - 이 기법을 사용하면 CPU가 계속 검사하면서 무한루프 → CPU 심하게 낭비
            
        - 이진 세마포
            - 세마포를 관리하는 자원의 개수에 따라
                - 카운터 세마포 : 자원이 여러개인 경우
                - 이진 세마포 : 자원이 1개인 경우
            - 구성요소
                - 세마포 변수 S : 0과 1중 하나를 가지는 변수, 1로 초기화됨
                - 대기 큐 : 자원이 사용가능해질 때까지 스레드들이 대기하는 큐
                - P 연산
                    - 자원 사용의 허가를 얻는 과정
                    - S를 1 감소시키고 0보다 작으면 스레드를 대기 큐에서 재움.
                    - 0보다 크거나 같으면 스레드는 자원을 사용하는 코드를 실행
                - V 연산
                    - 자원 사용이 끝났음을 알리는 과정
                    - S를 1 증가시키고 0보다 크면 그냥 리턴
                    - 0보다 작거나 같으면 대기 큐에서 스레드 하나 깨움
            - 이진 세마포는 하나의 자원에 대해 여러 스레드가 사용하고자 할 때 관리하는 기법
                
                → 뮤텍스와 매우 유사
                
        - 동기화 이슈 : 우선순위 역전
            - 우선순위가 높은 스레드가 우선순위가 낮은 스레드보다 늦게 실행되는 경우
            - 실시간 시스템의 근본 목적을 붕괴시킬 수 있음
            - 해결책 (우선순위 : T3 > T2 > T1)
                - 우선순위 올림 : T1스레드가 공유자원을 소유하게 될 때 T1의 우선순위를 일시적으로 미리 정해진 우선순위(T3보다 높은)로 높이는 방법
                - 우선순위 상속 : T1스레드가 공유자원을 획득하고 실행하는 동안 T3스레드가 공유 자원을 요청하면, T1의 스레드 우선순위를 T3 스레드보다 높게 변경
                
                  ⇒ 결국, 둘의 차이는 언제 우선순위를 높일것이냐, 시점의 차이 !
                
    4. 생산자 소비자 문제
        - 공유 버퍼에 데이터를 공급하는 생산자 - 공유버퍼에서 데이터를 읽고 쓰는 소비자 사이에서 공유 버퍼를 문제없이 사용하도록 생산자와 소비자를 동기화시키는 (실행순서 제어) 문제
        - 상호배제
            - 생산자들과 소비자들의 공유버퍼 사용에 대한 상호배제
            - 생산자는 +1, 소비자는 -1 하려고 하기 때문
            - 해결 : 뮤텍스나 세마포를 이용
        - 비어있는 공유 버퍼 문제 (소비자의 관점, 소비자가 P 연산을 수행)
            - 비어있는 공유버퍼를 소비자가 읽을 떄
            - 소비 속도가 빠를 때
            - 해결방법 : 세마포 R
                - 세마포 R에 대한 P 연산은 소비자 스레드가, V 연산은 생산자 스레드가 실행
                - R.counter 변수는 읽기 가능한 버퍼의 개수로 둠
                - 버퍼가 비어있는 상태에서 소비자가 읽으려고 할 때
                    - 소비자 : 버퍼에서 읽기 전에 P 연산 실행
                    - P 연산 : 버퍼가 비어있으면 (R.counter=0), 소비자가 잠을 자면서 대기하도록 작성
                - 빈 버퍼에 생산자가 쓸 때
                    - 생산자 : 버퍼에 데이터를 기록하고 V 연산 실행
                    - V 연산 : R.counter+=1, 대기중인 소비자를 깨움
                    - 소비자 : 깨어나면 P 연산을 마치고 공유버퍼에서 읽음. P 연산에서 R.counter-=1
        - 꽉 찬 공유 버퍼 문제 (생산자의 관점, 생산자가 P 연산 수행)
            - 꽉 찬 공유버퍼에 생산자가 쓸 때
            - 생산 속도가 빠를 때
            - 해결방법 : 세마포 W
                - 세마포 W에 대한 P 연산은 생산자 스레드가, V 연산은 소비자 스레드가 실행
                - W.counter 변수는 쓰기 가능한 버퍼의 개수로 둠
                - 공유버퍼가 꽉 찬 상태에서 생산자가 쓰려고 할 때
                    - 생산자 : 버퍼에 쓰기 전 P 연산 실행
                    - P 연산 : 버퍼가 꽉 찼으면 (W.counter=0), 생산자가 잠을 자면서 대기하도록 작성
                - 버퍼에 데이터가 있는 경우 소비자가 읽을 때
                    - 소비자 : 버퍼에서 데이터를 읽고 V 연산 실행
                    - V 연산 :  W.counter+=1, 대기중인 생산자를 깨움
                    - 생산자 : 깨어나면 P 연산을 마치고 공유버퍼에 씀. P 연산에서 W.counter-=1